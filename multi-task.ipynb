{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guWLd3PIqN36"
      },
      "source": [
        "# EXAMPLE - 1\n",
        "\n",
        "**Tasks :- Intent Detection, NER, Fragment Detection**\n",
        "\n",
        "**Tasks Description**\n",
        "\n",
        "``Intent Detection`` :- This is a single sentence classification task where an `intent` specifies which class the data sample belongs to. \n",
        "\n",
        "``NER`` :- This is a Named Entity Recognition/ Sequence Labelling/ Slot filling task where individual words of the sentence are tagged with an entity label it belongs to. The words which don't belong to any entity label are simply labeled as \"O\". \n",
        "\n",
        "``Fragment Detection`` :- This is modeled as a single sentence classification task which detects whether a sentence is incomplete (fragment) or not (non-fragment).\n",
        "\n",
        "**Conversational Utility** :-  Intent detection is one of the fundamental components for conversational system as it gives a broad understand of the category/domain the sentence/query belongs to.\n",
        "\n",
        "NER helps in extracting values for required entities (eg. location, date-time) from query.\n",
        "\n",
        "Fragment detection is a very useful piece in conversational system as knowing if a query/sentence is incomplete can aid in discarding bad queries beforehand.\n",
        "\n",
        "\n",
        "**Data** :- In this example, we are using the <a href=\"https://snips-nlu.readthedocs.io/en/latest/dataset.html\">SNIPS</a> data for intent and entity detection. For the sake of simplicity, we provide \n",
        "the data in simpler form under ``snips_data`` directory taken from <a href=\"https://github.com/LeePleased/StackPropagation-SLU/tree/master/data/snips\">here</a>.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9rm1fMNqbj3",
        "outputId": "7e024757-b04f-4471-aa6d-b3d04a75a66b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/nlp_proj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXqI-h6DrIW4",
        "outputId": "8d229b26-d349-43d9-8ec6-292b2f182ea6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1bwBUst6IlPPC4ILHcbv0GX9d8tIScYkv/nlp_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n",
        "!pip install tqdm\n",
        "!pip install ipywidgets\n",
        "!pip install Keras\n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install numpy\n",
        "!pip install sphinx_rtd_theme\n",
        "!pip install pandas\n",
        "!pip install scikit_learn\n",
        "!pip install PyYAML\n",
        "!pip install transformers\n",
        "!pip install joblib\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQiVsPzyuQgS",
        "outputId": "c78d28be-d973-4396-fa0a-37e52e829a5e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=94540bce6aea5aa988babc91facbfe51781e5f3097b011140d8037cfa6bd7c8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (7.7.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.0.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.6.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.6.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (7.9.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.4)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (5.7.16)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.1.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.15.0)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.0)\n",
            "Requirement already satisfied: jinja2<=3.0.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2<=3.0.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.5.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.11.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.28.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sphinx_rtd_theme\n",
            "  Downloading sphinx_rtd_theme-1.1.1-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 36.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sphinx<6,>=1.6 in /usr/local/lib/python3.8/dist-packages (from sphinx_rtd_theme) (1.8.6)\n",
            "Requirement already satisfied: docutils<0.18 in /usr/local/lib/python3.8/dist-packages (from sphinx_rtd_theme) (0.17.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.8/dist-packages (from sphinx<6,>=1.6->sphinx_rtd_theme) (2.6.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.8/dist-packages (from sphinx<6,>=1.6->sphinx_rtd_theme) (0.7.12)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.8/dist-packages (from sphinx<6,>=1.6->sphinx_rtd_theme) (2.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from sphinx<6,>=1.6->sphinx_rtd_theme) (57.4.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from sphinx<6,>=1.6->sphinx_rtd_theme) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from sphinx<6,>=1.6->sphinx_rtd_theme) (21.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from sphinx<6,>=1.6->sphinx_rtd_theme) (1.15.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.8/dist-packages (from sphinx<6,>=1.6->sphinx_rtd_theme) (1.2.4)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.8/dist-packages (from sphinx<6,>=1.6->sphinx_rtd_theme) (1.4.1)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.8/dist-packages (from sphinx<6,>=1.6->sphinx_rtd_theme) (2.11.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.8/dist-packages (from sphinx<6,>=1.6->sphinx_rtd_theme) (2.11.3)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.8/dist-packages (from babel!=2.0,>=1.3->sphinx<6,>=1.6->sphinx_rtd_theme) (2022.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.3->sphinx<6,>=1.6->sphinx_rtd_theme) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<6,>=1.6->sphinx_rtd_theme) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<6,>=1.6->sphinx_rtd_theme) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<6,>=1.6->sphinx_rtd_theme) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<6,>=1.6->sphinx_rtd_theme) (3.0.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->sphinx<6,>=1.6->sphinx_rtd_theme) (3.0.9)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.8/dist-packages (from sphinxcontrib-websupport->sphinx<6,>=1.6->sphinx_rtd_theme) (1.1.5)\n",
            "Installing collected packages: sphinx-rtd-theme\n",
            "Successfully installed sphinx-rtd-theme-1.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit_learn) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 37.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 20.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step -1 Data \n",
        "Convert input data file to individual file task with labels and create dictionary of labels for each task\n"
      ],
      "metadata": {
        "id": "oa-GywQH2Xjr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q3FT8Q_gqN3_"
      },
      "outputs": [],
      "source": [
        "def transform_snip(readFile,createLab=False):\n",
        "  # createLab = True\n",
        "  # readFile = 'snips_dev.txt'\n",
        "  f = open(readFile,\"r\")\n",
        "  labelNER = {}\n",
        "  labelIntent = {}\n",
        "  sentence = []\n",
        "  label = []\n",
        "  uid = 0\n",
        "  IntentDir = open('intent_{}.tsv'.format(readFile.split('.')[0]),\"w\")\n",
        "  NERDir = open('NER_{}.tsv'.format(readFile.split('.')[0]),\"w\")\n",
        "  for i,lines in enumerate(f):\n",
        "\n",
        "    line = lines.strip(' ')\n",
        "    items = line.strip('\\n').split(' ')\n",
        "    if line == '\\n':\n",
        "      NERDir.write(\"{}\\t{}\\t{}\\n\".format(uid,label,sentence))\n",
        "      sentence = []\n",
        "      label = []\n",
        "      uid +=1\n",
        "    elif len(items) == 2:\n",
        "      sentence.append(items[0])\n",
        "      label.append(items[1])\n",
        "      if createLab and items[1] not in labelNER:\n",
        "        labelNER[items[1]] = len(labelNER)\n",
        "    elif len(items) == 1:\n",
        "      intent = items[0]\n",
        "      sentences = ' '.join(sentence)\n",
        "      IntentDir.write(\"{}\\t{}\\t{}\\n\".format(uid,sentences,intent))\n",
        "      if createLab and intent not in labelIntent:\n",
        "        labelIntent[intent] = len(labelIntent)\n",
        "  return labelNER,labelIntent\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_snip('snips_dev.txt')\n",
        "transform_snip('snips_test.txt')\n",
        "labelNER,labelIntent = transform_snip('snips_train.txt',True)"
      ],
      "metadata": {
        "id": "DKJVtXJemI_6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labelNER)\n",
        "print(labelIntent)\n",
        "if \"[CLS]\" not in labelNER.keys():\n",
        "  labelNER['[CLS]'] = len(labelNER)\n",
        "if \"[SEP]\" not in labelNER.keys():\n",
        "  labelNER['[SEP]'] = len(labelNER)\n",
        "if \"X\" not in labelNER.keys():\n",
        "  labelNER['X'] = len(labelNER)\n",
        "if \"O\" not in labelNER.keys():\n",
        "  labelNER[\"O\"] = len(labelNER)\n",
        "\n",
        "len(labelNER)\n",
        "print(labelNER['O'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8WP7LvdpcMC",
        "outputId": "b2e0b742-bcdd-419b-e4c1-bca17fd49b25"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'O': 0, 'B-artist': 1, 'B-album': 2, 'B-service': 3, 'I-service': 4, 'B-entity_name': 5, 'I-entity_name': 6, 'B-playlist': 7, 'I-playlist': 8, 'B-object_select': 9, 'B-object_type': 10, 'B-rating_value': 11, 'B-best_rating': 12, 'B-music_item': 13, 'B-track': 14, 'I-track': 15, 'I-artist': 16, 'B-playlist_owner': 17, 'B-year': 18, 'B-sort': 19, 'B-movie_name': 20, 'I-movie_name': 21, 'B-party_size_number': 22, 'B-state': 23, 'B-city': 24, 'B-timeRange': 25, 'I-timeRange': 26, 'B-object_part_of_series_type': 27, 'I-object_type': 28, 'B-movie_type': 29, 'B-spatial_relation': 30, 'I-spatial_relation': 31, 'B-geographic_poi': 32, 'I-geographic_poi': 33, 'B-restaurant_type': 34, 'I-city': 35, 'B-party_size_description': 36, 'I-party_size_description': 37, 'B-object_location_type': 38, 'I-object_location_type': 39, 'B-object_name': 40, 'I-object_name': 41, 'I-movie_type': 42, 'B-rating_unit': 43, 'I-sort': 44, 'B-location_name': 45, 'I-location_name': 46, 'B-current_location': 47, 'I-current_location': 48, 'I-playlist_owner': 49, 'B-served_dish': 50, 'B-country': 51, 'B-condition_temperature': 52, 'B-poi': 53, 'I-poi': 54, 'B-condition_description': 55, 'B-genre': 56, 'B-restaurant_name': 57, 'I-restaurant_name': 58, 'I-state': 59, 'I-served_dish': 60, 'B-cuisine': 61, 'I-album': 62, 'I-country': 63, 'B-facility': 64, 'I-facility': 65, 'I-cuisine': 66, 'I-music_item': 67, 'I-object_select': 68, 'I-restaurant_type': 69, 'I-object_part_of_series_type': 70, 'I-genre': 71}\n",
            "{'PlayMusic': 0, 'AddToPlaylist': 1, 'RateBook': 2, 'SearchScreeningEvent': 3, 'BookRestaurant': 4, 'GetWeather': 5, 'SearchCreativeWork': 6}\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labelNER)\n",
        "len(labelIntent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPgak3KPfm8x",
        "outputId": "7e82385d-4eff-498d-adbb-067d052f6462"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_ngram(data,seq_len_left,seq_len_right):\n",
        "        sequence_dict = {}\n",
        "        for sentence in data:\n",
        "            word_list = sentence.split()\n",
        "            len_seq = len(word_list)\n",
        "            for ngram in range(seq_len_right):\n",
        "                i = 0\n",
        "                while i + ngram < len_seq:\n",
        "                    if len_seq - i - ngram - 1 >= seq_len_right:\n",
        "                        right_seq = seq_len_right\n",
        "                    else:\n",
        "                        right_seq = len_seq - i - ngram - 1\n",
        "\n",
        "                    if i >= seq_len_left:\n",
        "                        left_seq = seq_len_left\n",
        "                    else:\n",
        "                        left_seq = i\n",
        "\n",
        "                    key = \" \".join(word_list[i:i + ngram + 1])\n",
        "\n",
        "                    if sequence_dict.get(key, None) != None:\n",
        "                        sequence_dict[key] = min(sequence_dict[key], left_seq + right_seq)\n",
        "                    else:\n",
        "                        sequence_dict[key] = left_seq + right_seq\n",
        "                    i += 1\n",
        "        return sequence_dict"
      ],
      "metadata": {
        "id": "i1fyOzfvVye7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def validate_sequences(sequence_dict, seq_len_right, seq_len_left):\n",
        "    micro_sequences = []\n",
        "    macro_sequences = {}\n",
        "\n",
        "    for key in sequence_dict.keys():\n",
        "        score = sequence_dict[key]\n",
        "\n",
        "        if score < 1 and len(key.split()) <= seq_len_right:\n",
        "            micro_sequences.append(key)\n",
        "        else:\n",
        "            macro_sequences[key] = score\n",
        "\n",
        "    non_frag_sequences = []\n",
        "    macro_sequences_copy = macro_sequences.copy()\n",
        "\n",
        "    for sent in tqdm(micro_sequences, total = len(micro_sequences)):\n",
        "        for key in macro_sequences.keys():\n",
        "            if sent in key:\n",
        "                non_frag_sequences.append(key)\n",
        "                del macro_sequences_copy[key]\n",
        "\n",
        "        macro_sequences = macro_sequences_copy.copy()\n",
        "\n",
        "    for sent in non_frag_sequences:\n",
        "        macro_sequences[sent] = 0\n",
        "\n",
        "    for sent in micro_sequences:\n",
        "        macro_sequences[sent] = 0\n",
        "\n",
        "    return macro_sequences"
      ],
      "metadata": {
        "id": "y3tjpoPBfWuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a fragment file: 1:fragment, 0:not Fragment"
      ],
      "metadata": {
        "id": "ASEssOljqL5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "def create_fragment(readFile,percent = 0.5):\n",
        "  # readFile = 'intent_snips_dev.tsv'\n",
        "  writeDir = 'frag_{}.tsv'.format(readFile.split('.')[0])\n",
        "  # percent = 0.5\n",
        "  allDataDf = pd.read_csv(readFile, sep=\"\\t\", header=None)\n",
        "  sampledDataDf = allDataDf.sample(frac = 0.2, random_state=42)\n",
        "  dic = make_ngram(list(sampledDataDf[1]),2,3)\n",
        "  fragDict = validate_sequences(dic,2,3)\n",
        "  #decide number of fragments to take \n",
        "  fragDict = random.sample(list(fragDict.keys()),k=int(len(fragDict)*percent))\n",
        "  finalDf = pd.DataFrame({'uid' : [i for i in range(len(fragDict)+len(allDataDf))],\n",
        "                              'label' : [1]*len(fragDict)+[0]*len(allDataDf),\n",
        "                              'query' : fragDict+list(allDataDf.iloc[:, 1]) })\n",
        "  finalDf.to_csv(writeDir, sep='\\t',index=False, header=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ygvLx2UUqY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create_fragment('intent_snips_dev.tsv')\n",
        "create_fragment('intent_snips_test.tsv')\n",
        "create_fragment('intent_snips_train.tsv')\n",
        "create_fragment('intent_snips_dev.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmeuPHRopveV",
        "outputId": "29fba52d-1bda-4152-8915-1549ba16378e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 400.48it/s]\n",
            "100%|██████████| 9/9 [00:00<00:00, 389.82it/s]\n",
            "0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step -2 Data Preparation\n",
        "1.put all the data into a single array\n"
      ],
      "metadata": {
        "id": "f9xIGK4N6e4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "import transformers\n",
        "import json\n",
        "max_len= 128\n",
        "def make_dataTokens(readFile,tasks,tokenizer):\n",
        "  allDataArray = []\n",
        "  file = open(readFile,\"r\")\n",
        "  wf = '/content/drive/MyDrive/nlp_proj/prepared_data/{}.json'.format(readFile.split('.')[0])\n",
        "  with open(wf,\"w\") as writeF:\n",
        "    for f in file:\n",
        "      item = f.rstrip('\\n').split(\"\\t\")\n",
        "      row = {}\n",
        "      if tasks == \"NER\":\n",
        "        # row = {\"uid\":item[0],\"label\":literal_eval(item[1]),\"sentence\":literal_eval(item[2])}\n",
        "        label = literal_eval(item[1])\n",
        "        sentence = literal_eval(item[2])\n",
        "        tempLab,tempSent = NER_preprocess(label,sentence,tokenizer)\n",
        "        # out = tokenizer.encode_plus(tempSent,add_special_tokens = False, truncation='only_first',max_length=max_len,pad_to_max_length=False)\n",
        "        out = tokenizer.encode_plus(text = tempSent, add_special_tokens=False,\n",
        "                                        truncation_strategy ='only_first',\n",
        "                                        max_length = 128, pad_to_max_length=False)\n",
        "        row['uid'] = item[0]\n",
        "        row['label'] = tempLab\n",
        "        row['input_id'] = out['input_ids']\n",
        "        row['token_id'] = out['token_type_ids']\n",
        "        row['attention_mask'] = out['attention_mask']\n",
        "      if tasks == \"Intent\":\n",
        "        if (not item[2].isnumeric()):\n",
        "          label = labelIntent[item[2]]\n",
        "        row = {\"uid\":item[0],\"label\":label}\n",
        "        out = tokenizer.encode_plus(item[1],add_special_tokens = True, truncation='only_first',max_length=max_len,pad_to_max_length=False)\n",
        "        row['input_id'] = out['input_ids']\n",
        "        row['token_id'] = out['token_type_ids']\n",
        "        row['attention_mask'] = out['attention_mask']\n",
        "      if tasks == \"Fragment\":\n",
        "        assert item[1].isnumeric()\n",
        "        row = {\"uid\":item[0], \"label\":int(item[1])}\n",
        "        out = tokenizer.encode_plus(item[2],add_special_tokens = True, truncation='only_first',max_length=max_len,pad_to_max_length=False)\n",
        "        row['input_id'] = out['input_ids']\n",
        "        row['token_id'] = out['token_type_ids']\n",
        "        row['attention_mask'] = out['attention_mask']\n",
        "      writeF.write('{}\\n'.format(json.dumps(row)))\n",
        "  print(\"finishing writing {}\".format(wf))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#tokenize the word into sub tokens and only the first in the subtoken array gets assigned\n",
        "#with a label\n",
        "def NER_preprocess(label,sentence,tokenizer):\n",
        "  tempSent = ['[CLS]']\n",
        "  tempLab = [labelNER['[CLS]']]\n",
        "  for word,label in zip(sentence,label):\n",
        "    tokens = tokenizer.tokenize(word)\n",
        "    for m,tok in enumerate(tokens):\n",
        "      tempSent.append(tok)\n",
        "      if m==0:\n",
        "        tempLab.append(labelNER[label])\n",
        "      else:\n",
        "        tempLab.append(labelNER[\"X\"])\n",
        "  tempLab.append(labelNER['[SEP]'])\n",
        "  tempSent.append('[SEP]')\n",
        "  return tempLab,tempSent\n",
        "    \n",
        "# tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# make_dataTokens(\"1\",\"1\",tokenizer)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "94Vyu8QF6zBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tasks = {\"NER\":[\"NER_snips_dev.tsv\",\"NER_snips_test.tsv\",\"NER_snips_train.tsv\"],\n",
        "         \"Intent\":[\"intent_snips_dev.tsv\",\"intent_snips_test.tsv\",\"intent_snips_train.tsv\"],\n",
        "         \"Fragment\":[\"frag_intent_snips_dev.tsv\",\"frag_intent_snips_test.tsv\",\"frag_intent_snips_train.tsv\"]}\n",
        "import transformers\n",
        "model = \"bert\"\n",
        "task = \"NER\"\n",
        "if model == \"bert\":\n",
        "  tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "elif model == \"distilbert\":\n",
        "  tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "for task,fileArrays in tasks.items():\n",
        "    for file in fileArrays:\n",
        "      make_dataTokens(file,task,tokenizer)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338,
          "referenced_widgets": [
            "f733d86fb8b94a2b9ed674cfb5e3bce7",
            "e890b7f419054f068cb86a5812c8f797",
            "3efc1f5ebc63408d83d04a857dd43153",
            "6c2fc92c6b2e4ed0844bd420329002c2",
            "e65287369bd845e788dba589ffa9aab1",
            "1c1ffe30a6084b14be136aee49f8ac70",
            "85fa1712b39f411b88bf30c277459eaf",
            "3f3eadfeb95846e3b29d37c0d2e2f12d",
            "ffc0adaadb464f45ae5440c8f5cd6c4c",
            "5388bcd74595492ab8b7b1b179901c2d",
            "08d087799b5d455b8d3f66489a826024",
            "1fedc3d398724d0f8bed49cd911de2b0",
            "45e90efa847b4d99a7f9cd13c19d60d0",
            "36f45980158f43849ffcc42d17ad7b95",
            "218438bccbea49d19130778dd94eb2fb",
            "9c3ffd226cd143d7a00f1e860095f1d0",
            "938a9c002ae3484c98e1d8e7f2800020",
            "3da3bb322f7b48268aa526bae908d896",
            "f1c2112ba68a435484510d3972d4334e",
            "c6084a389ce34f6c96e43ede7c777490",
            "d38471034b0049caa1eec3bc67ec143d",
            "733fcc54ca794c65a344a3e3ae6b6d08",
            "66084c61bf2940e5b42a06a392aa7f50",
            "3ecd7dcff5b241b980ebb81ee4a0c7c3",
            "4ed60e32dc79445b84f96a4d9041bde0",
            "397154c194284c6c8a7a1176c21fd562",
            "cda7aeaedb4b47e9babff6cff641c60c",
            "47e9015c5cbb40c38b7afb44b290b92f",
            "baeca601da7844019c56bf131f25c80d",
            "573ebe12883043acbd8d29f8b8b37398",
            "b6f6b2d3686a4b3b9245d48ff5458242",
            "1be758c33811499ba5cedae771ac916a",
            "65ccd82bb0994e92a51f5ac88716559a"
          ]
        },
        "id": "rjjNLIegrqyw",
        "outputId": "8cc4a8ad-7727-40c7-9ba3-7963514800e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f733d86fb8b94a2b9ed674cfb5e3bce7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fedc3d398724d0f8bed49cd911de2b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66084c61bf2940e5b42a06a392aa7f50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-837dff1fb8d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfileArrays\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileArrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mmake_dataTokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'make_dataTokens' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataLoder: \n",
        "combines all tasks data together\n",
        "DataSampler:\n",
        "for all the batches, random generate the next batch task "
      ],
      "metadata": {
        "id": "bvdOIeckk2hV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JLy94bT5qN4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f828a9d-b202-43af-8fb5-9b77af4e56fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader,BatchSampler\n",
        "is_cuda = torch.cuda.is_available()\n",
        "print(is_cuda)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "class allTaskDS(Dataset):\n",
        "  def __init__(self,paths):\n",
        "    allTaskData, id2Task = self.make_array(paths)\n",
        "    self.allData = allTaskData\n",
        "    self.id2Task = id2Task\n",
        "\n",
        "  def make_array(self,paths):\n",
        "    count = 0\n",
        "    allTaskData = {}\n",
        "    id2Task = {}\n",
        "    for path in paths:\n",
        "      data = []\n",
        "      with open(path,\"r\") as f:\n",
        "        for js in f:\n",
        "          data.append(json.loads(js))\n",
        "      allTaskData[count] = data\n",
        "      task = path.split(\"/\")[-1].split(\"_\")[0]\n",
        "      id2Task[count] = task\n",
        "      count += 1\n",
        "    return allTaskData, id2Task\n",
        "\n",
        "  def __len__(self):\n",
        "    return sum(len(v) for k,v in self.allData.items())\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    task,sampleId = idx\n",
        "    data_dic = {}\n",
        "    task_dic = {}\n",
        "    task_dic['task_id'] = task\n",
        "    task_dic['task_type'] = self.id2Task[task]\n",
        "    data_dic['task'] = task_dic\n",
        "    data_dic['sample'] = self.allData[task][sampleId]\n",
        "    return data_dic\n",
        "      \n",
        "path_train = [\"/content/drive/MyDrive/nlp_proj/prepared_data/NER_snips_train.json\",\"/content/drive/MyDrive/nlp_proj/prepared_data/frag_intent_snips_train.json\",\"/content/drive/MyDrive/nlp_proj/prepared_data/intent_snips_train.json\"]\n",
        "path_dev = [\"/content/drive/MyDrive/nlp_proj/prepared_data/NER_snips_dev.json\",\"/content/drive/MyDrive/nlp_proj/prepared_data/frag_intent_snips_dev.json\",\"/content/drive/MyDrive/nlp_proj/prepared_data/frag_intent_snips_train.json\"]\n",
        "path_test = [\"/content/drive/MyDrive/nlp_proj/prepared_data/NER_snips_test.json\",\"/content/drive/MyDrive/nlp_proj/prepared_data/frag_intent_snips_test.json\",\"/content/drive/MyDrive/nlp_proj/prepared_data/intent_snips_test.json\"]\n",
        "train_ds = allTaskDS(path_train)\n",
        "dev_ds = allTaskDS(path_dev)\n",
        "test_ds = allTaskDS(path_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q0h9dy3-IcFj"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mix all tasks into batches with their task labels\n",
        "import random\n",
        "class Batcher(BatchSampler):\n",
        "  def __init__(self,datasetObj,batch_size):\n",
        "    self.allData = datasetObj.allData\n",
        "    self.id2Task = datasetObj.id2Task\n",
        "    self.seed = 42\n",
        "    self.shuffle_batches = True\n",
        "    self.shuffle_task = True\n",
        "    self.batch_size = batch_size\n",
        "    self.sampledID = []   #[[1,2,3],[4,5,6]]\n",
        "    self.allTaskID = []\n",
        "    self.allTasks = []\n",
        "    self.makeBatch()\n",
        "  def makeBatch(self):\n",
        "    for id,data in self.allData.items():\n",
        "      batch_idx = [list(range(i,min(i+self.batch_size,len(data)))) for i in range(0,len(data),self.batch_size)]\n",
        "      if self.shuffle_batches == True:\n",
        "        random.seed(self.seed)\n",
        "        random.shuffle(batch_idx)\n",
        "      self.sampledID.append(batch_idx)\n",
        "      self.allTasks.append(id)\n",
        "    for i in range(len(self.sampledID)):\n",
        "      self.allTaskID += [i] * len(self.sampledID[i])\n",
        "    if self.shuffle_task == True:\n",
        "        random.seed(self.seed)\n",
        "        random.shuffle(self.allTaskID)\n",
        "  def __iter__(self):\n",
        "    dataIter = [iter(samples) for samples in self.sampledID]\n",
        "    for taskId in self.allTaskID:\n",
        "      batchTaskId = self.allTasks[taskId]\n",
        "      batch = next(dataIter[taskId])\n",
        "      yield [(batchTaskId,sampleId) for sampleId in batch]\n",
        "      \n",
        "      \n",
        "train_batch = Batcher(train_ds,16)\n",
        "test_batch = Batcher(test_ds,32)\n",
        "dev_batch = Batcher(dev_ds,32)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FR9qLXxSOWT4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tensor(batch):\n",
        "  input_tensors = []\n",
        "  token_tensors = []\n",
        "  attention_mask = []\n",
        "  label_tensors = []\n",
        "  for sample in batch:\n",
        "    input_tensors.append(torch.LongTensor(sample['sample']['input_id']))\n",
        "    token_tensors.append(torch.LongTensor(sample['sample']['token_id']))\n",
        "    attention_mask.append(torch.LongTensor(sample['sample']['attention_mask']))\n",
        "    if isinstance(sample['sample']['label'],int):\n",
        "      sample['sample']['label'] = [sample['sample']['label']]\n",
        "    label_tensors.append(torch.LongTensor(sample['sample']['label']))\n",
        "  input_padded = torch.nn.utils.rnn.pad_sequence(input_tensors,batch_first=True)\n",
        "  token_padded = torch.nn.utils.rnn.pad_sequence(token_tensors,batch_first=True)\n",
        "  attention_padded = torch.nn.utils.rnn.pad_sequence(attention_mask,batch_first=True)\n",
        "  label_padded = torch.nn.utils.rnn.pad_sequence(label_tensors,batch_first=True)\n",
        "  assert input_padded.shape == token_padded.shape\n",
        "  assert input_padded.shape == attention_padded.shape\n",
        "  return [input_padded,token_padded,attention_padded,label_padded]\n",
        "def collate_fn(batch):\n",
        "  batch_meta = {}\n",
        "  batch_meta['task_id'] = batch[0]['task']['task_id']\n",
        "  batch_meta['task_type'] = batch[0]['task']['task_type']\n",
        "  batch_meta['uid'] = [sample['sample']['uid'] for sample in batch]\n",
        "  data = make_tensor(batch)\n",
        "  return batch_meta, data\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mE2PpfOZ16Md"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_sampler = train_batch,\n",
        "                                collate_fn=collate_fn,\n",
        "                                pin_memory=True)\n",
        "dev_loader = DataLoader(dev_ds, batch_sampler = dev_batch,\n",
        "                                collate_fn=collate_fn,\n",
        "                                pin_memory=True)\n",
        "\n",
        "\n",
        "test_loader = DataLoader(test_ds, batch_sampler = test_batch,\n",
        "                                collate_fn=collate_fn,\n",
        "                                pin_memory=True)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xI6lTgA7cD5o"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import *\n",
        "import torch.nn.functional as F\n",
        "class multiTaskModel(nn.Module):\n",
        "  def __init__(self,training=True):\n",
        "    super(multiTaskModel, self).__init__()\n",
        "    self.transformer_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "    self.hidden = self.transformer_model.config.hidden_size\n",
        "    self.tasks = ['NER', 'frag', 'intent']\n",
        "    self.dropout = {'NER':0.3,'frag':0.3,'intent':0.3}\n",
        "    self.num_class = {'NER':len(labelNER),'frag':2,'intent':len(labelIntent)}\n",
        "    self.training = training\n",
        "    self.headerDict, self.doDict=self.make_heads()\n",
        "    self.init_headers()\n",
        "  def make_heads(self):\n",
        "    allHeaders = nn.ModuleDict()\n",
        "    allDropouts = nn.ModuleDict()\n",
        "    for task in self.tasks:\n",
        "      dropout_layer = nn.Dropout(p=self.dropout[task])\n",
        "      linear_layer = nn.Linear(self.hidden, self.num_class[task])\n",
        "      allHeaders[task] = linear_layer\n",
        "      allDropouts[task] = dropout_layer\n",
        "    return allHeaders,allDropouts\n",
        "  def init_headers(self):\n",
        "    def init_weight(module):\n",
        "      if isinstance(module,(nn.Linear,nn.Embedding)):\n",
        "        module.weight.data.normal_(mean=0.0,std=0.02*1.0)\n",
        "      if isinstance(module,nn.Linear):\n",
        "        if module.bias is not None:\n",
        "          module.bias.data.zero_()\n",
        "    self.apply(init_weight)\n",
        "  def forward(self,tokenID,typeID,attentionMask,taskId,taskName):\n",
        "    out = self.transformer_model(input_ids=tokenID,token_type_ids=typeID,attention_mask = attentionMask)\n",
        "    last_hidden_state = out[0]\n",
        "    pooler = out[1]  #last layer hidden state of the first token\n",
        "    if taskId == 0:     #NER use all hidden state\n",
        "      output = self.doDict[taskName](last_hidden_state)\n",
        "      logits = self.headerDict[taskName](output)\n",
        "      return logits\n",
        "    else:\n",
        "      output = self.doDict[taskName](pooler)\n",
        "      logits = self.headerDict[taskName](output)\n",
        "      return logits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "      \n",
        "      \n",
        "\n"
      ],
      "metadata": {
        "id": "FSTzzE55kxaK"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.loss import _Loss\n",
        "class NERLoss(_Loss):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.ignore_index = -1\n",
        "  def forward(self,inp,target,mask):\n",
        "    nerLoss = mask.view(-1) == 1\n",
        "    nerlogits = inp.view(-1, inp.size(-1))\n",
        "    nerLabels = torch.where(\n",
        "            nerLoss, target.view(-1), torch.tensor(self.ignore_index).type_as(target)\n",
        "            )\n",
        "    finalLoss = F.cross_entropy(nerlogits, nerLabels, ignore_index=self.ignore_index)\n",
        "    return finalLoss\n"
      ],
      "metadata": {
        "id": "ElcZ4vOY5gET"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn\n",
        "cross_entropy_loss = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "NER_loss = NERLoss()\n",
        "loss_dic = {'NER':cross_entropy_loss, \n",
        "            'frag':cross_entropy_loss, \n",
        "            'intent':cross_entropy_loss}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4CXK7JtpnoYt"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pin_mem(meta,batch_data,gpu=False):\n",
        "    if gpu:\n",
        "        for i, part in enumerate(batch_data):\n",
        "            if part is not None:\n",
        "                if isinstance(part, torch.Tensor):\n",
        "                    batch_data[i] = part.pin_memory().cuda(non_blocking=True)\n",
        "                elif isinstance(part, tuple):\n",
        "                    batch_data[i] = tuple(sub_part.pin_memory().cuda(non_blocking=True) for sub_part in part)\n",
        "                elif isinstance(part, list):\n",
        "                    batch_data[i] = [sub_part.pin_memory().cuda(non_blocking=True) for sub_part in part]\n",
        "                else:\n",
        "                    raise TypeError(\"unknown batch data type at %s: %s\" % (i, part))\n",
        "\n",
        "    return meta, batch_data\n",
        "def _to_cuda(tensor):\n",
        "    if tensor is None: return tensor\n",
        "\n",
        "    if isinstance(tensor, list) or isinstance(tensor, tuple):\n",
        "        y = [e.cuda(non_blocking=True) for e in tensor]\n",
        "        for e in y:\n",
        "            e.requires_grad = False\n",
        "    else:\n",
        "        y = tensor.cuda(non_blocking=True)\n",
        "        y.requires_grad = False\n",
        "    return y "
      ],
      "metadata": {
        "id": "eRY8XoI1FRSO"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "model = multiTaskModel(training=True)\n",
        "if is_cuda:\n",
        "  model = model.cuda()\n",
        "eps = 1e-8\n",
        "lr = 2e-5\n",
        "batch_size =16\n",
        "epoch = 10\n",
        "grad_accumulation = 4\n",
        "trainS = math.ceil(len(train_ds)/batch_size) * epoch // grad_accumulation\n",
        "optimizer = AdamW(model.parameters(),lr=lr,eps=eps)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=trainS)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUygVpHKFw56",
        "outputId": "dca5cdd7-a29d-4cb0-a4e1-4affa1d1bfd0"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update(meta,data,gb_s,acc_s):\n",
        "  model.train()\n",
        "  target = data[3]\n",
        "  if is_cuda:\n",
        "    target = _to_cuda(target)\n",
        "  taskId = meta['task_id']\n",
        "  taskName = meta['task_type']\n",
        "  modelInputs = data[:3]\n",
        "  modelInputs += [taskId]\n",
        "  modelInputs += [taskName]\n",
        "  logits = model(*modelInputs)\n",
        "\n",
        "  task_loss = 0\n",
        "  if loss_dic[taskName] and (target is not None):\n",
        "    if taskName == \"NER\":\n",
        "      mask = data[2]\n",
        "      nerLoss = mask.view(-1) == 1\n",
        "      nerlogits = logits.view(-1, logits.size(-1))\n",
        "      nerLabels = torch.where(\n",
        "      nerLoss, target.view(-1), torch.tensor(-1).type_as(target))\n",
        "      task_loss = loss_dic[taskName](nerlogits,nerLabels)\n",
        "    else:\n",
        "      target = target.view(-1)\n",
        "      task_loss = loss_dic[taskName](logits,target)\n",
        "  task_loss /= grad_accumulation\n",
        "  task_loss.backward()\n",
        "  acc_s += 1\n",
        "  if acc_s == grad_accumulation:\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    gb_s += 1\n",
        "    acc_s = 0\n",
        "  return task_loss,gb_s,acc_s\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "cthvosyGHU71"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def predict_step(meta,data):\n",
        "  model.eval()\n",
        "  taskId = meta['task_id']\n",
        "  taskName = meta['task_type']\n",
        "  modelInputs = data[:3] + [taskId] + [taskName]\n",
        "  logits = model(*modelInputs)\n",
        "  if taskName == \"NER\":\n",
        "    #output (batchsize, len,numclass)\n",
        "    softmax = nn.functional.softmax(logits,dim=2).data.cpu().numpy()\n",
        "    sigmoid = nn.functional.sigmoid(logits).data.cpu().numpy()\n",
        "    predicted = np.argmax(softmax,axis=2).tolist()\n",
        "    score = np.max(sigmoid,axis=2).tolist()\n",
        "    attention_mask = data[2]\n",
        "    predictedTags = []\n",
        "    predictedscore = []\n",
        "    # if attention_mask is not None:\n",
        "    sentence_len = attention_mask.cpu().numpy().sum(axis=1).tolist()\n",
        "    for i,(tag,score) in enumerate(zip(predicted,score)):\n",
        "      predictedTags.append(tag[:sentence_len[i]])\n",
        "      predictedscore.append(score[:sentence_len[i]])\n",
        "    return predictedTags,predictedscore\n",
        "\n",
        "\n",
        "  else:\n",
        "    softmax = nn.functional.softmax(logits, dim=1).data.cpu().numpy()\n",
        "    sigmoid = nn.functional.sigmoid(logits).data.cpu().numpy()\n",
        "    prediction = np.argmax(softmax,axis=1)\n",
        "    predicted_l = prediction.tolist()\n",
        "    return predicted_l, softmax\n"
      ],
      "metadata": {
        "id": "s1d62HQdxFPA"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#citing using conlleval\n",
        "def __startOfChunk(prevTag, tag, prevTagType, tagType, chunkStart = False):\n",
        "    if prevTag == 'B' and tag == 'B':\n",
        "        chunkStart = True\n",
        "    if prevTag == 'I' and tag == 'B':\n",
        "        chunkStart = True\n",
        "    if prevTag == 'O' and tag == 'B':\n",
        "        chunkStart = True\n",
        "    if prevTag == 'O' and tag == 'I':\n",
        "        chunkStart = True\n",
        "\n",
        "    if prevTag == 'E' and tag == 'E':\n",
        "        chunkStart = True\n",
        "    if prevTag == 'E' and tag == 'I':\n",
        "        chunkStart = True\n",
        "    if prevTag == 'O' and tag == 'E':\n",
        "        chunkStart = True\n",
        "    if prevTag == 'O' and tag == 'I':\n",
        "        chunkStart = True\n",
        "\n",
        "    if tag != 'O' and tag != '.' and prevTagType != tagType:\n",
        "        chunkStart = True\n",
        "    return chunkStart\n",
        "\n",
        "def __endOfChunk(prevTag, tag, prevTagType, tagType, chunkEnd = False):\n",
        "    if prevTag == 'B' and tag == 'B':\n",
        "        chunkEnd = True\n",
        "    if prevTag == 'B' and tag == 'O':\n",
        "        chunkEnd = True\n",
        "    if prevTag == 'I' and tag == 'B':\n",
        "        chunkEnd = True\n",
        "    if prevTag == 'I' and tag == 'O':\n",
        "        chunkEnd = True\n",
        "\n",
        "    if prevTag == 'E' and tag == 'E':\n",
        "        chunkEnd = True\n",
        "    if prevTag == 'E' and tag == 'I':\n",
        "        chunkEnd = True\n",
        "    if prevTag == 'E' and tag == 'O':\n",
        "        chunkEnd = True\n",
        "    if prevTag == 'I' and tag == 'O':\n",
        "        chunkEnd = True\n",
        "\n",
        "    if prevTag != 'O' and prevTag != '.' and prevTagType != tagType:\n",
        "        chunkEnd = True\n",
        "    return chunkEnd\n",
        "\n",
        "def __splitTagType(tag):\n",
        "    s = tag.split('-')\n",
        "    if len(s) > 2 or len(s) == 0:\n",
        "        raise ValueError('tag format wrong. it must be B-xxx.xxx')\n",
        "    if len(s) == 1:\n",
        "        tag = s[0]\n",
        "        tagType = \"\"\n",
        "    else:\n",
        "        tag = s[0]\n",
        "        tagType = s[1]\n",
        "    return tag, tagType\n",
        "\n",
        "def computeF1Score(correct_slots, pred_slots):\n",
        "\n",
        "    correctChunk = {}\n",
        "    correctChunkCnt = 0\n",
        "    foundCorrect = {}\n",
        "    foundCorrectCnt = 0\n",
        "    foundPred = {}\n",
        "    foundPredCnt = 0\n",
        "    correctTags = 0\n",
        "    tokenCount = 0\n",
        "    for correct_slot, pred_slot in zip(correct_slots, pred_slots):\n",
        "        inCorrect = False\n",
        "        lastCorrectTag = 'O'\n",
        "        lastCorrectType = ''\n",
        "        lastPredTag = 'O'\n",
        "        lastPredType = ''\n",
        "        for c, p in zip(correct_slot, pred_slot):\n",
        "            correctTag, correctType = __splitTagType(c)\n",
        "            predTag, predType = __splitTagType(p)\n",
        "\n",
        "            if inCorrect == True:\n",
        "                if __endOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True and \\\n",
        "                   __endOfChunk(lastPredTag, predTag, lastPredType, predType) == True and \\\n",
        "                   (lastCorrectType == lastPredType):\n",
        "                    inCorrect = False\n",
        "                    correctChunkCnt += 1\n",
        "                    if lastCorrectType in correctChunk:\n",
        "                        correctChunk[lastCorrectType] += 1\n",
        "                    else:\n",
        "                        correctChunk[lastCorrectType] = 1\n",
        "                elif __endOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) != \\\n",
        "                     __endOfChunk(lastPredTag, predTag, lastPredType, predType) or \\\n",
        "                     (correctType != predType):\n",
        "                    inCorrect = False\n",
        "\n",
        "            if __startOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True and \\\n",
        "               __startOfChunk(lastPredTag, predTag, lastPredType, predType) == True and \\\n",
        "               (correctType == predType):\n",
        "                inCorrect = True\n",
        "\n",
        "            if __startOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True:\n",
        "                foundCorrectCnt += 1\n",
        "                if correctType in foundCorrect:\n",
        "                    foundCorrect[correctType] += 1\n",
        "                else:\n",
        "                    foundCorrect[correctType] = 1\n",
        "\n",
        "            if __startOfChunk(lastPredTag, predTag, lastPredType, predType) == True:\n",
        "                foundPredCnt += 1\n",
        "                if predType in foundPred:\n",
        "                    foundPred[predType] += 1\n",
        "                else:\n",
        "                    foundPred[predType] = 1\n",
        "\n",
        "            if correctTag == predTag and correctType == predType:\n",
        "                correctTags += 1\n",
        "\n",
        "            tokenCount += 1\n",
        "\n",
        "            lastCorrectTag = correctTag\n",
        "            lastCorrectType = correctType\n",
        "            lastPredTag = predTag\n",
        "            lastPredType = predType\n",
        "\n",
        "        if inCorrect == True:\n",
        "            correctChunkCnt += 1\n",
        "            if lastCorrectType in correctChunk:\n",
        "                correctChunk[lastCorrectType] += 1\n",
        "            else:\n",
        "                correctChunk[lastCorrectType] = 1\n",
        "\n",
        "    if foundPredCnt > 0:\n",
        "        precision = 100*correctChunkCnt/foundPredCnt\n",
        "    else:\n",
        "        precision = 0\n",
        "\n",
        "    if foundCorrectCnt > 0:\n",
        "        recall = 100*correctChunkCnt/foundCorrectCnt\n",
        "    else:\n",
        "        recall = 0\n",
        "\n",
        "    if (precision+recall) > 0:\n",
        "        f1 = (2*precision*recall)/(precision+recall)\n",
        "    else:\n",
        "        f1 = 0\n",
        "\n",
        "    return f1, precision, recall\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zK37W1qcD7Zg"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HpZbzHB8GdM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def evaluate(dataset,batchSampler,dataLoader,batch_size,evaluate_metric=True):\n",
        "  numStep = math.ceil(len(dataset)/batch_size)\n",
        "  allLabel = [[],[],[]]\n",
        "  allPred = [[],[],[]]\n",
        "  allScore = [[],[],[]]\n",
        "  allId = [[],[],[]]\n",
        "  tasks = ['NER', 'frag', 'intent']\n",
        "  for meta,data in tqdm(dataLoader,total=numStep):\n",
        "    meta,data = pin_mem(meta,data,is_cuda)\n",
        "    taskID = int(meta['task_id'])\n",
        "    tags,score = predict_step(meta,data)\n",
        "    if (meta['task_type'] == \"frag\" or meta['task_type'] == 'intent'):\n",
        "      label = data[3].view(data[3].shape[0]).data.cpu().numpy()\n",
        "    elif (meta['task_type'] == \"NER\"):\n",
        "      label = data[3].data.cpu().numpy()\n",
        "    allLabel[taskID].extend(label)\n",
        "    allScore[taskID].extend(score)\n",
        "    allPred[taskID].extend(tags)\n",
        "    allId[taskID].extend(meta['uid'])\n",
        "  for i in range(len(allPred)):\n",
        "    if allPred[i] == []:\n",
        "      continue\n",
        "    taskName = tasks[i]\n",
        "    if taskName == \"NER\":\n",
        "      for j,(p,l) in enumerate(zip(allPred[i],allLabel[i])):\n",
        "        itoLab = {v:k for k,v in labelNER.items()}\n",
        "        allLabel[i][j] = l[:len(p)]\n",
        "        allPred[i][j] = [itoLab[int(id)] for id in p]\n",
        "        allLabel[i][j] = [itoLab[int(id)] for id in allLabel[i][j]]\n",
        "      # print(\"-------\")\n",
        "      # print(allPred)\n",
        "      newPred = []\n",
        "      newLab = []\n",
        "      newScore = []\n",
        "      for m,sample in enumerate(allLabel[i]):\n",
        "        onepred = []\n",
        "        oneLab = []\n",
        "        oneScore = []\n",
        "        for n,ele in enumerate(sample):\n",
        "          if ele != '[CLS]' and ele != '[SEP]' and ele != 'X':\n",
        "            onepred.append(allPred[i][m][n])\n",
        "            oneScore.append(allScore[i][m][n])\n",
        "            oneLab.append(ele)\n",
        "        newPred.append(onepred)\n",
        "        newLab.append(oneLab)\n",
        "        newScore.append(oneScore)\n",
        "      allLabel[i] = newLab\n",
        "      allPred[i] = newPred\n",
        "      allScore[i] = newScore\n",
        "    if taskName == 'frag':\n",
        "      Labeldic = {1:\"frag\",0:\"complete\"}\n",
        "      allPred[i] = [Labeldic[pred] for pred in allPred[i]]\n",
        "      allLabel[i] = [Labeldic[lab] for lab in allLabel[i]]\n",
        "    if taskName == 'intent':\n",
        "      itoLab = {v:k for k,v in labelIntent.items()}\n",
        "      allPred[i] = [itoLab[pred] for pred in allPred[i]]\n",
        "      allLabel[i] = [itoLab[lab] for lab in allLabel[i]]\n",
        "    \n",
        "  if evaluate_metric:\n",
        "    print('********** Evaluation{}************'.format(tasks[i]))\n",
        "    for i in range(len(allPred)):\n",
        "      if allPred[i] == []:\n",
        "        continue\n",
        "      taskName = tasks[i]\n",
        "      if taskName == \"NER\":\n",
        "        f1, precision, recall = computeF1Score(allLabel[i],allPred[i])\n",
        "        print('f1:{}, precision:{}, recall:{} '.format(f1, precision, recall))\n",
        "      \n",
        "      elif taskName == \"frag\" or taskName == \"intent\":\n",
        "        metric_val = accuracy_score(allLabel[i],allPred[i])*100\n",
        "        print('accuracy:{}'.format(metric_val))\n",
        "   \n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zttE2VuVtaRq"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EIQeE_zX6pJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_s = 0\n",
        "acc_s = 0\n",
        "logging_update_s = 50\n",
        "\n",
        "for e in range(epoch):\n",
        "  totalEpochLoss = 0\n",
        "  t = math.ceil(len(train_ds)/batch_size)\n",
        "  description = \"Epoch: {}\".format(e)\n",
        "  with tqdm(total=t,position=e,desc=description) as progress:\n",
        "    for i,(meta,data)in enumerate(train_loader):\n",
        "      meta,data = pin_mem(meta,data,is_cuda)\n",
        "      task_loss,gb_s,acc_s = update(meta,data,gb_s,acc_s)\n",
        "      totalEpochLoss += task_loss\n",
        "      if gb_s % logging_update_s == 0 and (acc_s+1 == grad_accumulation):\n",
        "        avg_loss = task_loss / (i+1)\n",
        "        taskName = meta['task_type']\n",
        "        print('Steps: {} Task: {} Avg.Loss: {} Task Loss: {}'.format(gb_s,taskName,avg_loss,task_loss))\n",
        "      progress.update(1)\n",
        "    evaluate(dev_ds,dev_batch,dev_loader,32,evaluate_metric=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl8iOwDWHTlj",
        "outputId": "0e737cc8-5864-4faa-82c3-e4acf45a8166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:   0%|          | 7/3282 [00:00<03:06, 17.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 0 Task: NER Avg.Loss: 0.3435479402542114 Task Loss: 1.0306438207626343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:   6%|▌         | 205/3282 [00:11<02:47, 18.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 50 Task: frag Avg.Loss: 0.00022028795501682907 Task Loss: 0.04471845552325249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  12%|█▏        | 406/3282 [00:22<02:37, 18.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 100 Task: frag Avg.Loss: 2.6726311261882074e-05 Task Loss: 0.010770703665912151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  18%|█▊        | 605/3282 [00:34<03:00, 14.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 150 Task: frag Avg.Loss: 1.9536866602720693e-05 Task Loss: 0.011780730448663235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  25%|██▍       | 805/3282 [00:45<02:15, 18.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 200 Task: frag Avg.Loss: 2.095280433422886e-05 Task Loss: 0.016825102269649506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  31%|███       | 1005/3282 [00:56<02:14, 16.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 250 Task: intent Avg.Loss: 9.921723540173844e-05 Task Loss: 0.09951488673686981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  37%|███▋      | 1206/3282 [01:07<01:59, 17.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 300 Task: frag Avg.Loss: 2.672851042007096e-05 Task Loss: 0.032154396176338196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  43%|████▎     | 1405/3282 [01:19<01:50, 16.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 350 Task: intent Avg.Loss: 2.395657793385908e-05 Task Loss: 0.033611077815294266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  49%|████▉     | 1605/3282 [01:30<01:41, 16.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 400 Task: intent Avg.Loss: 2.6298796001356095e-05 Task Loss: 0.042156971991062164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  55%|█████▍    | 1805/3282 [01:42<01:31, 16.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 450 Task: frag Avg.Loss: 3.871704757330008e-05 Task Loss: 0.06980683654546738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  61%|██████    | 2006/3282 [01:54<01:18, 16.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 500 Task: intent Avg.Loss: 2.357919584028423e-05 Task Loss: 0.04722912982106209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  67%|██████▋   | 2206/3282 [02:05<00:56, 19.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 550 Task: NER Avg.Loss: 0.0001104569819290191 Task Loss: 0.2433367222547531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  73%|███████▎  | 2405/3282 [02:17<00:51, 17.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 600 Task: intent Avg.Loss: 1.180172785097966e-05 Task Loss: 0.02835955284535885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  79%|███████▉  | 2606/3282 [02:28<00:38, 17.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 650 Task: frag Avg.Loss: 1.1450767942733364e-06 Task Loss: 0.002980634802952409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  86%|████████▌ | 2807/3282 [02:39<00:26, 18.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 700 Task: frag Avg.Loss: 4.674655428971164e-06 Task Loss: 0.013103059493005276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  92%|█████████▏| 3005/3282 [02:51<00:17, 16.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 750 Task: frag Avg.Loss: 5.008433845432592e-07 Task Loss: 0.001504032756201923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0:  98%|█████████▊| 3205/3282 [03:03<00:04, 17.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 800 Task: frag Avg.Loss: 9.430872864868434e-07 Task Loss: 0.003020708682015538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 0: 3283it [03:08, 19.01it/s]                          \n",
            "  0%|          | 0/901 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "\n",
            "  0%|          | 3/901 [00:00<00:40, 22.26it/s]\u001b[A\n",
            "  1%|          | 7/901 [00:00<00:31, 28.06it/s]\u001b[A\n",
            "  1%|          | 11/901 [00:00<00:30, 28.85it/s]\u001b[A\n",
            "  2%|▏         | 15/901 [00:00<00:28, 31.53it/s]\u001b[A\n",
            "  2%|▏         | 19/901 [00:00<00:26, 32.72it/s]\u001b[A\n",
            "  3%|▎         | 23/901 [00:00<00:28, 31.24it/s]\u001b[A\n",
            "  3%|▎         | 27/901 [00:00<00:29, 29.74it/s]\u001b[A\n",
            "  3%|▎         | 31/901 [00:01<00:26, 32.39it/s]\u001b[A\n",
            "  4%|▍         | 36/901 [00:01<00:24, 34.92it/s]\u001b[A\n",
            "  4%|▍         | 40/901 [00:01<00:24, 35.41it/s]\u001b[A\n",
            "  5%|▍         | 45/901 [00:01<00:23, 36.01it/s]\u001b[A\n",
            "  5%|▌         | 49/901 [00:01<00:23, 36.03it/s]\u001b[A\n",
            "  6%|▌         | 53/901 [00:01<00:24, 34.08it/s]\u001b[A\n",
            "  6%|▋         | 57/901 [00:01<00:25, 33.50it/s]\u001b[A\n",
            "  7%|▋         | 61/901 [00:01<00:25, 32.44it/s]\u001b[A\n",
            "  7%|▋         | 65/901 [00:02<00:26, 31.81it/s]\u001b[A\n",
            "  8%|▊         | 69/901 [00:02<00:26, 31.25it/s]\u001b[A\n",
            "  8%|▊         | 74/901 [00:02<00:25, 32.95it/s]\u001b[A\n",
            "  9%|▊         | 78/901 [00:02<00:25, 32.38it/s]\u001b[A\n",
            "  9%|▉         | 82/901 [00:02<00:23, 34.26it/s]\u001b[A\n",
            " 10%|▉         | 86/901 [00:02<00:24, 33.72it/s]\u001b[A\n",
            " 10%|▉         | 90/901 [00:02<00:22, 35.27it/s]\u001b[A\n",
            " 10%|█         | 94/901 [00:02<00:23, 33.89it/s]\u001b[A\n",
            " 11%|█         | 98/901 [00:02<00:25, 31.94it/s]\u001b[A\n",
            " 11%|█▏        | 102/901 [00:03<00:24, 33.02it/s]\u001b[A\n",
            " 12%|█▏        | 106/901 [00:03<00:25, 31.52it/s]\u001b[A\n",
            " 12%|█▏        | 110/901 [00:03<00:24, 32.23it/s]\u001b[A\n",
            " 13%|█▎        | 114/901 [00:03<00:27, 28.31it/s]\u001b[A\n",
            " 13%|█▎        | 119/901 [00:03<00:24, 32.02it/s]\u001b[A\n",
            " 14%|█▎        | 123/901 [00:03<00:25, 30.49it/s]\u001b[A\n",
            " 14%|█▍        | 127/901 [00:03<00:25, 30.00it/s]\u001b[A\n",
            " 15%|█▍        | 131/901 [00:04<00:24, 31.68it/s]\u001b[A\n",
            " 15%|█▍        | 135/901 [00:04<00:24, 30.76it/s]\u001b[A\n",
            " 15%|█▌        | 139/901 [00:04<00:25, 29.36it/s]\u001b[A\n",
            " 16%|█▌        | 143/901 [00:04<00:23, 31.59it/s]\u001b[A\n",
            " 16%|█▋        | 147/901 [00:04<00:23, 32.56it/s]\u001b[A\n",
            " 17%|█▋        | 151/901 [00:04<00:25, 29.41it/s]\u001b[A\n",
            " 17%|█▋        | 155/901 [00:04<00:24, 30.30it/s]\u001b[A\n",
            " 18%|█▊        | 159/901 [00:04<00:22, 32.47it/s]\u001b[A\n",
            " 18%|█▊        | 163/901 [00:05<00:22, 32.39it/s]\u001b[A\n",
            " 19%|█▊        | 167/901 [00:05<00:24, 30.39it/s]\u001b[A\n",
            " 19%|█▉        | 171/901 [00:05<00:25, 28.31it/s]\u001b[A\n",
            " 19%|█▉        | 174/901 [00:05<00:25, 28.20it/s]\u001b[A\n",
            " 20%|█▉        | 177/901 [00:05<00:25, 28.45it/s]\u001b[A\n",
            " 20%|██        | 182/901 [00:05<00:21, 33.52it/s]\u001b[A\n",
            " 21%|██        | 186/901 [00:05<00:22, 31.13it/s]\u001b[A\n",
            " 21%|██        | 190/901 [00:05<00:22, 31.10it/s]\u001b[A\n",
            " 22%|██▏       | 194/901 [00:06<00:25, 27.93it/s]\u001b[A\n",
            " 22%|██▏       | 198/901 [00:06<00:24, 28.81it/s]\u001b[A\n",
            " 22%|██▏       | 202/901 [00:06<00:23, 30.14it/s]\u001b[A\n",
            " 23%|██▎       | 206/901 [00:06<00:21, 31.73it/s]\u001b[A\n",
            " 23%|██▎       | 210/901 [00:06<00:21, 32.57it/s]\u001b[A\n",
            " 24%|██▍       | 214/901 [00:06<00:21, 31.97it/s]\u001b[A\n",
            " 24%|██▍       | 218/901 [00:06<00:25, 27.30it/s]\u001b[A\n",
            " 25%|██▍       | 221/901 [00:07<00:24, 27.66it/s]\u001b[A\n",
            " 25%|██▍       | 225/901 [00:07<00:23, 29.34it/s]\u001b[A\n",
            " 25%|██▌       | 229/901 [00:07<00:24, 27.25it/s]\u001b[A\n",
            " 26%|██▌       | 232/901 [00:07<00:24, 27.47it/s]\u001b[A\n",
            " 26%|██▌       | 236/901 [00:07<00:22, 29.28it/s]\u001b[A\n",
            " 27%|██▋       | 240/901 [00:07<00:20, 31.80it/s]\u001b[A\n",
            " 27%|██▋       | 246/901 [00:07<00:17, 38.26it/s]\u001b[A\n",
            " 28%|██▊       | 250/901 [00:07<00:17, 37.33it/s]\u001b[A\n",
            " 28%|██▊       | 256/901 [00:08<00:15, 42.29it/s]\u001b[A\n",
            " 29%|██▉       | 261/901 [00:08<00:17, 36.42it/s]\u001b[A\n",
            " 30%|██▉       | 266/901 [00:08<00:16, 38.78it/s]\u001b[A\n",
            " 30%|███       | 271/901 [00:08<00:16, 38.82it/s]\u001b[A\n",
            " 31%|███       | 276/901 [00:08<00:16, 38.02it/s]\u001b[A\n",
            " 31%|███       | 280/901 [00:08<00:17, 35.68it/s]\u001b[A\n",
            " 32%|███▏      | 284/901 [00:08<00:18, 33.04it/s]\u001b[A\n",
            " 32%|███▏      | 288/901 [00:09<00:19, 31.58it/s]\u001b[A\n",
            " 32%|███▏      | 292/901 [00:09<00:19, 31.51it/s]\u001b[A\n",
            " 33%|███▎      | 298/901 [00:09<00:15, 38.08it/s]\u001b[A\n",
            " 34%|███▎      | 303/901 [00:09<00:15, 37.87it/s]\u001b[A\n",
            " 34%|███▍      | 307/901 [00:09<00:16, 37.03it/s]\u001b[A\n",
            " 35%|███▍      | 311/901 [00:09<00:17, 33.97it/s]\u001b[A\n",
            " 35%|███▌      | 316/901 [00:09<00:16, 35.79it/s]\u001b[A\n",
            " 36%|███▌      | 320/901 [00:09<00:16, 34.32it/s]\u001b[A\n",
            " 36%|███▌      | 324/901 [00:09<00:16, 35.15it/s]\u001b[A\n",
            " 36%|███▋      | 328/901 [00:10<00:16, 33.83it/s]\u001b[A\n",
            " 37%|███▋      | 332/901 [00:10<00:17, 32.07it/s]\u001b[A\n",
            "Epoch: 0: 3283it [03:18, 19.01it/s]\n",
            " 38%|███▊      | 340/901 [00:10<00:16, 33.52it/s]\u001b[A\n",
            " 38%|███▊      | 344/901 [00:10<00:15, 35.01it/s]\u001b[A\n",
            " 39%|███▊      | 348/901 [00:10<00:16, 32.77it/s]\u001b[A\n",
            " 39%|███▉      | 353/901 [00:10<00:15, 36.51it/s]\u001b[A\n",
            " 40%|███▉      | 358/901 [00:10<00:14, 37.73it/s]\u001b[A\n",
            " 40%|████      | 362/901 [00:11<00:15, 35.12it/s]\u001b[A\n",
            " 41%|████      | 366/901 [00:11<00:16, 32.26it/s]\u001b[A\n",
            " 41%|████      | 370/901 [00:11<00:16, 31.67it/s]\u001b[A\n",
            " 42%|████▏     | 374/901 [00:11<00:17, 30.71it/s]\u001b[A\n",
            " 42%|████▏     | 379/901 [00:11<00:15, 32.82it/s]\u001b[A\n",
            " 43%|████▎     | 383/901 [00:11<00:15, 32.99it/s]\u001b[A\n",
            " 43%|████▎     | 388/901 [00:11<00:14, 34.92it/s]\u001b[A\n",
            " 44%|████▎     | 393/901 [00:12<00:13, 36.53it/s]\u001b[A\n",
            " 44%|████▍     | 397/901 [00:12<00:14, 34.73it/s]\u001b[A\n",
            " 45%|████▍     | 401/901 [00:12<00:14, 35.21it/s]\u001b[A\n",
            " 45%|████▍     | 405/901 [00:12<00:13, 35.58it/s]\u001b[A\n",
            " 46%|████▌     | 411/901 [00:12<00:12, 39.17it/s]\u001b[A\n",
            " 46%|████▌     | 416/901 [00:12<00:11, 40.59it/s]\u001b[A\n",
            " 47%|████▋     | 421/901 [00:12<00:13, 36.63it/s]\u001b[A\n",
            " 47%|████▋     | 425/901 [00:12<00:12, 37.35it/s]\u001b[A\n",
            " 48%|████▊     | 429/901 [00:13<00:13, 34.53it/s]\u001b[A\n",
            " 48%|████▊     | 433/901 [00:13<00:14, 32.94it/s]\u001b[A\n",
            " 49%|████▊     | 438/901 [00:13<00:12, 36.46it/s]\u001b[A\n",
            " 49%|████▉     | 442/901 [00:13<00:13, 34.75it/s]\u001b[A\n",
            " 50%|████▉     | 446/901 [00:13<00:13, 34.16it/s]\u001b[A\n",
            " 50%|█████     | 451/901 [00:13<00:12, 35.86it/s]\u001b[A\n",
            " 50%|█████     | 455/901 [00:13<00:12, 34.49it/s]\u001b[A\n",
            " 51%|█████     | 459/901 [00:13<00:13, 32.64it/s]\u001b[A\n",
            " 51%|█████▏    | 463/901 [00:14<00:14, 30.59it/s]\u001b[A\n",
            " 52%|█████▏    | 467/901 [00:14<00:14, 30.95it/s]\u001b[A\n",
            " 52%|█████▏    | 472/901 [00:14<00:12, 34.60it/s]\u001b[A\n",
            " 53%|█████▎    | 476/901 [00:14<00:12, 33.97it/s]\u001b[A\n",
            " 53%|█████▎    | 480/901 [00:14<00:12, 33.06it/s]\u001b[A\n",
            " 54%|█████▍    | 485/901 [00:14<00:12, 33.99it/s]\u001b[A\n",
            " 54%|█████▍    | 489/901 [00:14<00:12, 32.91it/s]\u001b[A\n",
            " 55%|█████▍    | 493/901 [00:14<00:12, 33.27it/s]\u001b[A\n",
            " 55%|█████▌    | 497/901 [00:15<00:11, 34.75it/s]\u001b[A\n",
            " 56%|█████▌    | 501/901 [00:15<00:12, 31.52it/s]\u001b[A\n",
            " 56%|█████▌    | 506/901 [00:15<00:11, 34.61it/s]\u001b[A\n",
            " 57%|█████▋    | 510/901 [00:15<00:11, 34.02it/s]\u001b[A\n",
            " 57%|█████▋    | 514/901 [00:15<00:11, 34.36it/s]\u001b[A\n",
            " 58%|█████▊    | 519/901 [00:15<00:10, 36.32it/s]\u001b[A\n",
            " 58%|█████▊    | 524/901 [00:15<00:09, 39.44it/s]\u001b[A\n",
            " 59%|█████▊    | 529/901 [00:15<00:11, 33.70it/s]\u001b[A\n",
            " 59%|█████▉    | 534/901 [00:16<00:10, 34.02it/s]\u001b[A\n",
            " 60%|█████▉    | 538/901 [00:16<00:10, 34.17it/s]\u001b[A\n",
            " 60%|██████    | 542/901 [00:16<00:10, 35.41it/s]\u001b[A\n",
            " 61%|██████    | 546/901 [00:16<00:10, 33.11it/s]\u001b[A\n",
            " 61%|██████    | 551/901 [00:16<00:09, 36.05it/s]\u001b[A\n",
            " 62%|██████▏   | 556/901 [00:16<00:08, 38.76it/s]\u001b[A\n",
            " 62%|██████▏   | 560/901 [00:16<00:09, 35.87it/s]\u001b[A\n",
            " 63%|██████▎   | 564/901 [00:16<00:09, 36.23it/s]\u001b[A\n",
            " 63%|██████▎   | 568/901 [00:17<00:09, 34.48it/s]\u001b[A\n",
            " 63%|██████▎   | 572/901 [00:17<00:10, 31.89it/s]\u001b[A\n",
            " 64%|██████▍   | 576/901 [00:17<00:09, 33.31it/s]\u001b[A\n",
            " 64%|██████▍   | 580/901 [00:17<00:09, 33.16it/s]\u001b[A\n",
            " 65%|██████▍   | 584/901 [00:17<00:10, 30.70it/s]\u001b[A\n",
            " 65%|██████▌   | 588/901 [00:17<00:09, 31.70it/s]\u001b[A\n",
            " 66%|██████▌   | 592/901 [00:17<00:09, 32.43it/s]\u001b[A\n",
            " 66%|██████▌   | 596/901 [00:17<00:10, 29.08it/s]\u001b[A\n",
            " 67%|██████▋   | 601/901 [00:18<00:09, 33.00it/s]\u001b[A\n",
            " 67%|██████▋   | 605/901 [00:18<00:09, 30.99it/s]\u001b[A\n",
            " 68%|██████▊   | 609/901 [00:18<00:09, 29.45it/s]\u001b[A\n",
            " 68%|██████▊   | 613/901 [00:18<00:09, 31.43it/s]\u001b[A\n",
            " 68%|██████▊   | 617/901 [00:18<00:09, 28.65it/s]\u001b[A\n",
            " 69%|██████▉   | 622/901 [00:18<00:08, 33.40it/s]\u001b[A\n",
            " 69%|██████▉   | 626/901 [00:18<00:08, 33.93it/s]\u001b[A\n",
            " 70%|██████▉   | 630/901 [00:19<00:08, 33.51it/s]\u001b[A\n",
            " 70%|███████   | 634/901 [00:19<00:07, 33.81it/s]\u001b[A\n",
            " 71%|███████   | 638/901 [00:19<00:07, 32.97it/s]\u001b[A\n",
            " 71%|███████▏  | 642/901 [00:19<00:07, 32.70it/s]\u001b[A\n",
            " 72%|███████▏  | 646/901 [00:19<00:07, 31.93it/s]\u001b[A\n",
            " 72%|███████▏  | 650/901 [00:19<00:07, 31.99it/s]\u001b[A\n",
            " 73%|███████▎  | 655/901 [00:19<00:07, 33.61it/s]\u001b[A\n",
            " 73%|███████▎  | 660/901 [00:19<00:07, 34.02it/s]\u001b[A\n",
            " 74%|███████▎  | 664/901 [00:20<00:06, 34.31it/s]\u001b[A\n",
            " 74%|███████▍  | 669/901 [00:20<00:06, 36.11it/s]\u001b[A\n",
            " 75%|███████▍  | 673/901 [00:20<00:06, 32.68it/s]\u001b[A\n",
            " 75%|███████▌  | 677/901 [00:20<00:06, 33.16it/s]\u001b[A\n",
            " 76%|███████▌  | 681/901 [00:20<00:06, 31.74it/s]\u001b[A\n",
            " 76%|███████▌  | 685/901 [00:20<00:06, 31.04it/s]\u001b[A\n",
            " 76%|███████▋  | 689/901 [00:20<00:06, 30.31it/s]\u001b[A\n",
            " 77%|███████▋  | 693/901 [00:21<00:07, 28.75it/s]\u001b[A\n",
            " 77%|███████▋  | 698/901 [00:21<00:06, 33.48it/s]\u001b[A\n",
            " 78%|███████▊  | 703/901 [00:21<00:05, 35.17it/s]\u001b[A\n",
            " 78%|███████▊  | 707/901 [00:21<00:05, 33.12it/s]\u001b[A\n",
            " 79%|███████▉  | 711/901 [00:21<00:05, 33.89it/s]\u001b[A\n",
            " 79%|███████▉  | 715/901 [00:21<00:05, 34.24it/s]\u001b[A\n",
            " 80%|███████▉  | 719/901 [00:21<00:05, 31.46it/s]\u001b[A\n",
            " 80%|████████  | 723/901 [00:21<00:05, 30.49it/s]\u001b[A\n",
            " 81%|████████  | 727/901 [00:22<00:05, 29.97it/s]\u001b[A\n",
            " 81%|████████  | 731/901 [00:22<00:06, 27.67it/s]\u001b[A\n",
            " 82%|████████▏ | 735/901 [00:22<00:05, 28.97it/s]\u001b[A\n",
            " 82%|████████▏ | 738/901 [00:22<00:05, 28.65it/s]\u001b[A\n",
            " 82%|████████▏ | 742/901 [00:22<00:05, 30.79it/s]\u001b[A\n",
            " 83%|████████▎ | 746/901 [00:22<00:05, 29.40it/s]\u001b[A\n",
            " 83%|████████▎ | 749/901 [00:22<00:05, 29.44it/s]\u001b[A\n",
            " 84%|████████▎ | 754/901 [00:22<00:04, 31.94it/s]\u001b[A\n",
            " 84%|████████▍ | 758/901 [00:23<00:04, 30.23it/s]\u001b[A\n",
            " 85%|████████▍ | 762/901 [00:23<00:04, 29.82it/s]\u001b[A\n",
            " 85%|████████▌ | 766/901 [00:23<00:04, 30.22it/s]\u001b[A\n",
            " 85%|████████▌ | 770/901 [00:23<00:04, 30.73it/s]\u001b[A\n",
            " 86%|████████▌ | 774/901 [00:23<00:04, 29.69it/s]\u001b[A\n",
            " 86%|████████▋ | 779/901 [00:23<00:03, 33.53it/s]\u001b[A\n",
            " 87%|████████▋ | 784/901 [00:23<00:03, 37.08it/s]\u001b[A\n",
            " 87%|████████▋ | 788/901 [00:23<00:02, 37.73it/s]\u001b[A\n",
            " 88%|████████▊ | 792/901 [00:24<00:03, 35.07it/s]\u001b[A\n",
            " 88%|████████▊ | 796/901 [00:24<00:03, 34.86it/s]\u001b[A\n",
            " 89%|████████▉ | 800/901 [00:24<00:02, 34.79it/s]\u001b[A\n",
            " 89%|████████▉ | 804/901 [00:24<00:03, 31.10it/s]\u001b[A\n",
            " 90%|████████▉ | 808/901 [00:24<00:02, 31.52it/s]\u001b[A\n",
            " 90%|█████████ | 813/901 [00:24<00:02, 35.11it/s]\u001b[A\n",
            " 91%|█████████ | 817/901 [00:24<00:02, 33.21it/s]\u001b[A\n",
            " 91%|█████████ | 821/901 [00:24<00:02, 33.51it/s]\u001b[A\n",
            " 92%|█████████▏| 826/901 [00:25<00:02, 36.32it/s]\u001b[A\n",
            " 92%|█████████▏| 830/901 [00:25<00:01, 36.46it/s]\u001b[A\n",
            " 93%|█████████▎| 834/901 [00:25<00:02, 33.50it/s]\u001b[A\n",
            " 93%|█████████▎| 839/901 [00:25<00:01, 36.50it/s]\u001b[A\n",
            " 94%|█████████▎| 843/901 [00:25<00:01, 33.78it/s]\u001b[A\n",
            " 94%|█████████▍| 848/901 [00:25<00:01, 36.98it/s]\u001b[A\n",
            " 95%|█████████▍| 853/901 [00:25<00:01, 39.20it/s]\u001b[A\n",
            " 95%|█████████▌| 857/901 [00:25<00:01, 39.41it/s]\u001b[A\n",
            " 96%|█████████▌| 861/901 [00:26<00:01, 35.59it/s]\u001b[A\n",
            " 96%|█████████▌| 865/901 [00:26<00:01, 34.61it/s]\u001b[A\n",
            " 96%|█████████▋| 869/901 [00:26<00:00, 33.18it/s]\u001b[A\n",
            " 97%|█████████▋| 873/901 [00:26<00:00, 31.76it/s]\u001b[A\n",
            " 97%|█████████▋| 877/901 [00:26<00:00, 30.41it/s]\u001b[A\n",
            " 98%|█████████▊| 881/901 [00:26<00:00, 32.71it/s]\u001b[A\n",
            " 98%|█████████▊| 885/901 [00:26<00:00, 34.34it/s]\u001b[A\n",
            " 99%|█████████▊| 889/901 [00:26<00:00, 33.91it/s]\u001b[A\n",
            " 99%|█████████▉| 893/901 [00:27<00:00, 31.67it/s]\u001b[A\n",
            "100%|█████████▉| 898/901 [00:27<00:00, 34.30it/s]\u001b[A\n",
            "902it [00:27, 33.05it/s]\n",
            "Epoch: 0: 3283it [03:35, 15.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********** Evaluationintent************\n",
            "f1:48.550000000000004, precision:44.01631912964642, recall:54.12486064659978 \n",
            "accuracy:99.04921700223713\n",
            "accuracy:99.05076508334282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:   0%|          | 0/3282 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch: 1:   0%|          | 3/3282 [00:00<03:22, 16.22it/s]\u001b[A\n",
            "Epoch: 1:   0%|          | 5/3282 [00:00<03:56, 13.85it/s]\u001b[A\n",
            "Epoch: 1:   0%|          | 7/3282 [00:00<04:03, 13.43it/s]\u001b[A\n",
            "Epoch: 1:   0%|          | 9/3282 [00:00<04:14, 12.86it/s]\u001b[A\n",
            "Epoch: 1:   0%|          | 11/3282 [00:00<04:05, 13.34it/s]\u001b[A\n",
            "Epoch: 1:   0%|          | 13/3282 [00:01<04:37, 11.80it/s]\u001b[A\n",
            "Epoch: 1:   0%|          | 15/3282 [00:01<04:21, 12.48it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 17/3282 [00:01<04:37, 11.74it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 19/3282 [00:01<04:21, 12.49it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 21/3282 [00:01<04:28, 12.13it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 23/3282 [00:01<04:16, 12.71it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 25/3282 [00:01<04:25, 12.27it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 27/3282 [00:02<04:14, 12.78it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 29/3282 [00:02<04:12, 12.88it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 32/3282 [00:02<03:30, 15.45it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 34/3282 [00:02<03:26, 15.71it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 36/3282 [00:02<03:30, 15.41it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 38/3282 [00:02<03:34, 15.12it/s]\u001b[A\n",
            "Epoch: 1:   1%|          | 41/3282 [00:03<03:35, 15.02it/s]\u001b[A\n",
            "Epoch: 1:   1%|▏         | 44/3282 [00:03<03:12, 16.84it/s]\u001b[A\n",
            "Epoch: 1:   1%|▏         | 46/3282 [00:03<03:27, 15.61it/s]\u001b[A\n",
            "Epoch: 1:   1%|▏         | 49/3282 [00:03<03:34, 15.07it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 52/3282 [00:03<03:07, 17.20it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 54/3282 [00:03<03:25, 15.69it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 57/3282 [00:03<03:18, 16.28it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 59/3282 [00:04<03:16, 16.43it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 61/3282 [00:04<03:22, 15.90it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 63/3282 [00:04<03:12, 16.70it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 65/3282 [00:04<03:20, 16.08it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 67/3282 [00:04<03:19, 16.10it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 69/3282 [00:04<03:42, 14.41it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 72/3282 [00:04<03:13, 16.56it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 74/3282 [00:05<03:28, 15.37it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 76/3282 [00:05<03:15, 16.38it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 78/3282 [00:05<03:41, 14.44it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 80/3282 [00:05<03:27, 15.44it/s]\u001b[A\n",
            "Epoch: 1:   2%|▏         | 82/3282 [00:05<03:29, 15.30it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 85/3282 [00:05<03:21, 15.86it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 87/3282 [00:05<03:12, 16.62it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 89/3282 [00:05<03:14, 16.39it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 92/3282 [00:06<03:07, 17.05it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 94/3282 [00:06<03:19, 15.95it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 96/3282 [00:06<03:15, 16.28it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 98/3282 [00:06<03:28, 15.28it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 100/3282 [00:06<03:17, 16.10it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 102/3282 [00:06<03:26, 15.38it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 104/3282 [00:06<03:20, 15.82it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 106/3282 [00:07<03:40, 14.41it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 109/3282 [00:07<03:30, 15.06it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 112/3282 [00:07<03:17, 16.03it/s]\u001b[A\n",
            "Epoch: 1:   3%|▎         | 114/3282 [00:07<03:27, 15.25it/s]\u001b[A\n",
            "Epoch: 1:   4%|▎         | 116/3282 [00:07<03:17, 16.00it/s]\u001b[A\n",
            "Epoch: 1:   4%|▎         | 118/3282 [00:07<03:22, 15.61it/s]\u001b[A\n",
            "Epoch: 1:   4%|▎         | 120/3282 [00:08<03:41, 14.26it/s]\u001b[A\n",
            "Epoch: 1:   4%|▎         | 122/3282 [00:08<03:33, 14.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 850 Task: intent Avg.Loss: 0.00014522518904414028 Task Loss: 0.017427021637558937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:   4%|▍         | 125/3282 [00:08<03:05, 17.04it/s]\u001b[A\n",
            "Epoch: 1:   4%|▍         | 128/3282 [00:08<02:57, 17.72it/s]\u001b[A\n",
            "Epoch: 1:   4%|▍         | 130/3282 [00:08<03:10, 16.54it/s]\u001b[A\n",
            "Epoch: 1:   4%|▍         | 133/3282 [00:08<03:20, 15.72it/s]\u001b[A\n",
            "Epoch: 1:   4%|▍         | 136/3282 [00:08<02:58, 17.67it/s]\u001b[A\n",
            "Epoch: 1:   4%|▍         | 138/3282 [00:09<03:05, 16.98it/s]\u001b[A\n",
            "Epoch: 1:   4%|▍         | 141/3282 [00:09<03:10, 16.47it/s]\u001b[A\n",
            "Epoch: 1:   4%|▍         | 143/3282 [00:09<03:02, 17.16it/s]\u001b[A\n",
            "Epoch: 1:   4%|▍         | 145/3282 [00:09<03:17, 15.88it/s]\u001b[A\n",
            "Epoch: 1:   5%|▍         | 148/3282 [00:09<02:46, 18.80it/s]\u001b[A\n",
            "Epoch: 1:   5%|▍         | 150/3282 [00:09<03:06, 16.79it/s]\u001b[A\n",
            "Epoch: 1:   5%|▍         | 153/3282 [00:09<03:03, 17.02it/s]\u001b[A\n",
            "Epoch: 1:   5%|▍         | 156/3282 [00:10<02:37, 19.79it/s]\u001b[A\n",
            "Epoch: 1:   5%|▍         | 159/3282 [00:10<02:48, 18.51it/s]\u001b[A\n",
            "Epoch: 1:   5%|▍         | 161/3282 [00:10<03:04, 16.94it/s]\u001b[A\n",
            "Epoch: 1:   5%|▍         | 164/3282 [00:10<02:48, 18.47it/s]\u001b[A\n",
            "Epoch: 1:   5%|▌         | 166/3282 [00:10<02:59, 17.38it/s]\u001b[A\n",
            "Epoch: 1:   5%|▌         | 169/3282 [00:10<03:17, 15.77it/s]\u001b[A\n",
            "Epoch: 1:   5%|▌         | 172/3282 [00:10<02:57, 17.53it/s]\u001b[A\n",
            "Epoch: 1:   5%|▌         | 174/3282 [00:11<03:15, 15.87it/s]\u001b[A\n",
            "Epoch: 1:   5%|▌         | 177/3282 [00:11<03:05, 16.73it/s]\u001b[A\n",
            "Epoch: 1:   5%|▌         | 180/3282 [00:11<02:50, 18.21it/s]\u001b[A\n",
            "Epoch: 1:   6%|▌         | 182/3282 [00:11<02:57, 17.48it/s]\u001b[A\n",
            "Epoch: 1:   6%|▌         | 185/3282 [00:11<03:20, 15.45it/s]\u001b[A\n",
            "Epoch: 1:   6%|▌         | 188/3282 [00:11<03:11, 16.12it/s]\u001b[A\n",
            "Epoch: 1:   6%|▌         | 190/3282 [00:12<03:10, 16.24it/s]\u001b[A\n",
            "Epoch: 1:   6%|▌         | 192/3282 [00:12<03:05, 16.68it/s]\u001b[A\n",
            "Epoch: 1:   6%|▌         | 194/3282 [00:12<02:57, 17.37it/s]\u001b[A\n",
            "Epoch: 1:   6%|▌         | 196/3282 [00:12<02:54, 17.64it/s]\u001b[A\n",
            "Epoch: 1:   6%|▌         | 198/3282 [00:12<02:51, 17.94it/s]\u001b[A\n",
            "Epoch: 1:   6%|▌         | 200/3282 [00:12<02:51, 18.02it/s]\u001b[A\n",
            "Epoch: 1:   6%|▌         | 202/3282 [00:12<03:04, 16.67it/s]\u001b[A\n",
            "Epoch: 1:   6%|▌         | 205/3282 [00:12<03:07, 16.42it/s]\u001b[A\n",
            "Epoch: 1:   6%|▋         | 208/3282 [00:13<02:46, 18.45it/s]\u001b[A\n",
            "Epoch: 1:   6%|▋         | 210/3282 [00:13<02:45, 18.56it/s]\u001b[A\n",
            "Epoch: 1:   6%|▋         | 212/3282 [00:13<02:57, 17.31it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 214/3282 [00:13<02:52, 17.82it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 217/3282 [00:13<03:01, 16.90it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 220/3282 [00:13<02:44, 18.65it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 222/3282 [00:13<02:42, 18.86it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 225/3282 [00:14<02:45, 18.42it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 228/3282 [00:14<02:26, 20.90it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 231/3282 [00:14<02:44, 18.59it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 233/3282 [00:14<03:09, 16.05it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 236/3282 [00:14<02:49, 17.96it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 238/3282 [00:14<03:01, 16.73it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 241/3282 [00:14<02:59, 16.91it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 244/3282 [00:15<02:46, 18.21it/s]\u001b[A\n",
            "Epoch: 1:   7%|▋         | 246/3282 [00:15<03:00, 16.80it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 249/3282 [00:15<03:15, 15.50it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 252/3282 [00:15<03:06, 16.25it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 254/3282 [00:15<03:12, 15.74it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 256/3282 [00:15<03:05, 16.32it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 258/3282 [00:16<03:05, 16.34it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 261/3282 [00:16<02:50, 17.77it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 264/3282 [00:16<02:36, 19.33it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 266/3282 [00:16<02:47, 17.99it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 268/3282 [00:16<02:43, 18.43it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 270/3282 [00:16<03:19, 15.06it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 273/3282 [00:16<03:32, 14.14it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 276/3282 [00:17<03:11, 15.72it/s]\u001b[A\n",
            "Epoch: 1:   8%|▊         | 278/3282 [00:17<03:01, 16.59it/s]\u001b[A\n",
            "Epoch: 1:   9%|▊         | 280/3282 [00:17<03:07, 15.99it/s]\u001b[A\n",
            "Epoch: 1:   9%|▊         | 282/3282 [00:17<03:11, 15.68it/s]\u001b[A\n",
            "Epoch: 1:   9%|▊         | 285/3282 [00:17<03:06, 16.08it/s]\u001b[A\n",
            "Epoch: 1:   9%|▉         | 288/3282 [00:17<02:47, 17.89it/s]\u001b[A\n",
            "Epoch: 1:   9%|▉         | 290/3282 [00:17<03:04, 16.19it/s]\u001b[A\n",
            "Epoch: 1:   9%|▉         | 293/3282 [00:18<03:19, 14.99it/s]\u001b[A\n",
            "Epoch: 1:   9%|▉         | 296/3282 [00:18<03:13, 15.47it/s]\u001b[A\n",
            "Epoch: 1:   9%|▉         | 298/3282 [00:18<03:02, 16.33it/s]\u001b[A\n",
            "Epoch: 1:   9%|▉         | 300/3282 [00:18<02:56, 16.90it/s]\u001b[A\n",
            "Epoch: 1:   9%|▉         | 302/3282 [00:18<03:08, 15.77it/s]\u001b[A\n",
            "Epoch: 1:   9%|▉         | 305/3282 [00:18<03:09, 15.71it/s]\u001b[A\n",
            "Epoch: 1:   9%|▉         | 308/3282 [00:19<03:01, 16.39it/s]\u001b[A\n",
            "Epoch: 1:   9%|▉         | 310/3282 [00:19<03:07, 15.83it/s]\u001b[A\n",
            "Epoch: 1:  10%|▉         | 313/3282 [00:19<03:11, 15.50it/s]\u001b[A\n",
            "Epoch: 1:  10%|▉         | 316/3282 [00:19<02:52, 17.22it/s]\u001b[A\n",
            "Epoch: 1:  10%|▉         | 318/3282 [00:19<03:06, 15.87it/s]\u001b[A\n",
            "Epoch: 1:  10%|▉         | 320/3282 [00:19<03:07, 15.80it/s]\u001b[A\n",
            "Epoch: 1:  10%|▉         | 322/3282 [00:19<03:01, 16.32it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 900 Task: NER Avg.Loss: 0.0006875919061712921 Task Loss: 0.22002941370010376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  10%|▉         | 325/3282 [00:20<03:16, 15.02it/s]\u001b[A\n",
            "Epoch: 1:  10%|▉         | 328/3282 [00:20<02:57, 16.62it/s]\u001b[A\n",
            "Epoch: 1:  10%|█         | 330/3282 [00:20<03:03, 16.10it/s]\u001b[A\n",
            "Epoch: 1:  10%|█         | 333/3282 [00:20<02:45, 17.81it/s]\u001b[A\n",
            "Epoch: 1:  10%|█         | 336/3282 [00:20<02:24, 20.45it/s]\u001b[A\n",
            "Epoch: 1:  10%|█         | 339/3282 [00:20<02:41, 18.22it/s]\u001b[A\n",
            "Epoch: 1:  10%|█         | 341/3282 [00:21<02:49, 17.34it/s]\u001b[A\n",
            "Epoch: 1:  10%|█         | 344/3282 [00:21<02:35, 18.85it/s]\u001b[A\n",
            "Epoch: 1:  11%|█         | 346/3282 [00:21<02:46, 17.65it/s]\u001b[A\n",
            "Epoch: 1:  11%|█         | 348/3282 [00:21<02:44, 17.85it/s]\u001b[A\n",
            "Epoch: 1:  11%|█         | 350/3282 [00:21<03:02, 16.09it/s]\u001b[A\n",
            "Epoch: 1:  11%|█         | 352/3282 [00:21<02:54, 16.78it/s]\u001b[A\n",
            "Epoch: 1:  11%|█         | 354/3282 [00:21<02:57, 16.49it/s]\u001b[A\n",
            "Epoch: 1:  11%|█         | 356/3282 [00:21<03:04, 15.89it/s]\u001b[A\n",
            "Epoch: 1:  11%|█         | 358/3282 [00:22<03:00, 16.19it/s]\u001b[A\n",
            "Epoch: 1:  11%|█         | 361/3282 [00:22<02:55, 16.64it/s]\u001b[A\n",
            "Epoch: 1:  11%|█         | 363/3282 [00:22<02:51, 17.04it/s]\u001b[A\n",
            "Epoch: 1:  11%|█         | 365/3282 [00:22<03:13, 15.10it/s]\u001b[A\n",
            "Epoch: 1:  11%|█         | 368/3282 [00:22<02:45, 17.57it/s]\u001b[A\n",
            "Epoch: 1:  11%|█▏        | 370/3282 [00:22<02:52, 16.86it/s]\u001b[A\n",
            "Epoch: 1:  11%|█▏        | 372/3282 [00:22<02:51, 16.93it/s]\u001b[A\n",
            "Epoch: 1:  11%|█▏        | 374/3282 [00:23<02:54, 16.63it/s]\u001b[A\n",
            "Epoch: 1:  11%|█▏        | 377/3282 [00:23<03:13, 15.05it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 380/3282 [00:23<02:43, 17.73it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 382/3282 [00:23<02:52, 16.77it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 385/3282 [00:23<02:48, 17.24it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 388/3282 [00:23<02:30, 19.21it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 390/3282 [00:23<02:32, 19.01it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 393/3282 [00:24<02:32, 18.92it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 395/3282 [00:24<02:30, 19.13it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 397/3282 [00:24<02:50, 16.94it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 400/3282 [00:24<02:23, 20.03it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 403/3282 [00:24<02:38, 18.12it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 405/3282 [00:24<02:59, 16.05it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 408/3282 [00:24<02:41, 17.76it/s]\u001b[A\n",
            "Epoch: 1:  12%|█▏        | 410/3282 [00:25<02:44, 17.45it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 413/3282 [00:25<02:52, 16.66it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 415/3282 [00:25<02:46, 17.21it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 417/3282 [00:25<03:14, 14.77it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 420/3282 [00:25<03:00, 15.89it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 422/3282 [00:25<03:08, 15.13it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 425/3282 [00:26<03:00, 15.86it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 428/3282 [00:26<02:40, 17.77it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 430/3282 [00:26<02:57, 16.10it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 432/3282 [00:26<02:54, 16.34it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 434/3282 [00:26<02:58, 15.92it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 437/3282 [00:26<03:11, 14.86it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 440/3282 [00:26<02:49, 16.76it/s]\u001b[A\n",
            "Epoch: 1:  13%|█▎        | 442/3282 [00:27<02:55, 16.17it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▎        | 445/3282 [00:27<02:57, 15.95it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▎        | 448/3282 [00:27<02:32, 18.57it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▎        | 450/3282 [00:27<02:46, 17.02it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▍        | 452/3282 [00:27<02:43, 17.32it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▍        | 454/3282 [00:27<02:57, 15.91it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▍        | 456/3282 [00:27<02:47, 16.86it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▍        | 458/3282 [00:28<02:59, 15.77it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▍        | 461/3282 [00:28<02:52, 16.32it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▍        | 464/3282 [00:28<02:45, 17.07it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▍        | 466/3282 [00:28<02:58, 15.78it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▍        | 468/3282 [00:28<02:48, 16.66it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▍        | 470/3282 [00:28<02:57, 15.84it/s]\u001b[A\n",
            "Epoch: 1:  14%|█▍        | 473/3282 [00:28<02:56, 15.91it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▍        | 476/3282 [00:29<02:56, 15.91it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▍        | 478/3282 [00:29<02:48, 16.64it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▍        | 480/3282 [00:29<02:42, 17.22it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▍        | 482/3282 [00:29<02:59, 15.56it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▍        | 485/3282 [00:29<03:06, 14.96it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▍        | 488/3282 [00:29<02:41, 17.28it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▍        | 490/3282 [00:29<02:55, 15.95it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▍        | 492/3282 [00:30<02:49, 16.47it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▌        | 494/3282 [00:30<03:08, 14.77it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▌        | 496/3282 [00:30<02:57, 15.69it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▌        | 498/3282 [00:30<02:56, 15.77it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▌        | 501/3282 [00:30<03:03, 15.18it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▌        | 504/3282 [00:30<02:43, 16.99it/s]\u001b[A\n",
            "Epoch: 1:  15%|█▌        | 506/3282 [00:30<02:53, 15.98it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▌        | 509/3282 [00:31<03:06, 14.85it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▌        | 512/3282 [00:31<02:48, 16.44it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▌        | 514/3282 [00:31<03:00, 15.37it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▌        | 517/3282 [00:31<03:07, 14.72it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▌        | 520/3282 [00:31<02:56, 15.63it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▌        | 522/3282 [00:32<02:53, 15.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 950 Task: NER Avg.Loss: 0.0004370818205643445 Task Loss: 0.2272825539112091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  16%|█▌        | 524/3282 [00:32<02:44, 16.73it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▌        | 526/3282 [00:32<02:55, 15.69it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▌        | 529/3282 [00:32<02:44, 16.74it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▌        | 533/3282 [00:32<02:27, 18.65it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▋        | 536/3282 [00:32<02:25, 18.83it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▋        | 538/3282 [00:32<02:37, 17.47it/s]\u001b[A\n",
            "Epoch: 1:  16%|█▋        | 541/3282 [00:33<02:46, 16.43it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 543/3282 [00:33<02:39, 17.16it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 545/3282 [00:33<02:41, 16.98it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 548/3282 [00:33<02:40, 17.01it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 550/3282 [00:33<02:46, 16.39it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 552/3282 [00:33<02:43, 16.69it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 554/3282 [00:33<02:44, 16.55it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 556/3282 [00:33<02:37, 17.33it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 558/3282 [00:34<03:10, 14.32it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 560/3282 [00:34<02:54, 15.58it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 562/3282 [00:34<03:00, 15.08it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 564/3282 [00:34<02:47, 16.20it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 566/3282 [00:34<02:53, 15.64it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 568/3282 [00:34<02:49, 15.99it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 570/3282 [00:34<02:50, 15.93it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 572/3282 [00:35<02:41, 16.76it/s]\u001b[A\n",
            "Epoch: 1:  17%|█▋        | 574/3282 [00:35<02:50, 15.90it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 576/3282 [00:35<02:40, 16.88it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 578/3282 [00:35<02:57, 15.21it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 581/3282 [00:35<02:57, 15.19it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 584/3282 [00:35<02:37, 17.08it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 586/3282 [00:35<02:45, 16.29it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 588/3282 [00:35<02:37, 17.10it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 590/3282 [00:36<02:57, 15.15it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 592/3282 [00:36<02:48, 16.00it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 594/3282 [00:36<02:59, 15.01it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 596/3282 [00:36<02:47, 16.01it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 598/3282 [00:36<02:54, 15.42it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 600/3282 [00:36<02:49, 15.81it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 602/3282 [00:36<03:00, 14.85it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 604/3282 [00:37<02:53, 15.47it/s]\u001b[A\n",
            "Epoch: 1:  18%|█▊        | 606/3282 [00:37<03:12, 13.91it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▊        | 609/3282 [00:37<02:51, 15.60it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▊        | 612/3282 [00:37<02:33, 17.43it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▊        | 614/3282 [00:37<02:51, 15.52it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▉        | 616/3282 [00:37<02:41, 16.51it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▉        | 618/3282 [00:37<02:41, 16.47it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▉        | 621/3282 [00:38<02:37, 16.85it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▉        | 624/3282 [00:38<02:33, 17.27it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▉        | 626/3282 [00:38<02:37, 16.85it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▉        | 629/3282 [00:38<02:41, 16.40it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▉        | 632/3282 [00:38<02:26, 18.11it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▉        | 634/3282 [00:38<02:36, 16.90it/s]\u001b[A\n",
            "Epoch: 1:  19%|█▉        | 637/3282 [00:39<02:35, 17.02it/s]\u001b[A\n",
            "Epoch: 1:  20%|█▉        | 641/3282 [00:39<02:25, 18.17it/s]\u001b[A\n",
            "Epoch: 1:  20%|█▉        | 644/3282 [00:39<02:14, 19.61it/s]\u001b[A\n",
            "Epoch: 1:  20%|█▉        | 646/3282 [00:39<02:21, 18.63it/s]\u001b[A\n",
            "Epoch: 1:  20%|█▉        | 649/3282 [00:39<02:27, 17.88it/s]\u001b[A\n",
            "Epoch: 1:  20%|█▉        | 652/3282 [00:39<02:11, 19.99it/s]\u001b[A\n",
            "Epoch: 1:  20%|█▉        | 655/3282 [00:39<02:27, 17.77it/s]\u001b[A\n",
            "Epoch: 1:  20%|██        | 657/3282 [00:40<02:32, 17.24it/s]\u001b[A\n",
            "Epoch: 1:  20%|██        | 660/3282 [00:40<02:18, 18.88it/s]\u001b[A\n",
            "Epoch: 1:  20%|██        | 662/3282 [00:40<02:19, 18.72it/s]\u001b[A\n",
            "Epoch: 1:  20%|██        | 664/3282 [00:40<02:23, 18.30it/s]\u001b[A\n",
            "Epoch: 1:  20%|██        | 667/3282 [00:40<02:13, 19.61it/s]\u001b[A\n",
            "Epoch: 1:  20%|██        | 669/3282 [00:40<02:30, 17.32it/s]\u001b[A\n",
            "Epoch: 1:  20%|██        | 672/3282 [00:40<02:18, 18.82it/s]\u001b[A\n",
            "Epoch: 1:  21%|██        | 674/3282 [00:41<02:22, 18.31it/s]\u001b[A\n",
            "Epoch: 1:  21%|██        | 677/3282 [00:41<02:38, 16.48it/s]\u001b[A\n",
            "Epoch: 1:  21%|██        | 680/3282 [00:41<02:20, 18.48it/s]\u001b[A\n",
            "Epoch: 1:  21%|██        | 682/3282 [00:41<02:31, 17.13it/s]\u001b[A\n",
            "Epoch: 1:  21%|██        | 685/3282 [00:41<02:32, 16.98it/s]\u001b[A\n",
            "Epoch: 1:  21%|██        | 688/3282 [00:41<02:35, 16.69it/s]\u001b[A\n",
            "Epoch: 1:  21%|██        | 690/3282 [00:41<02:35, 16.62it/s]\u001b[A\n",
            "Epoch: 1:  21%|██        | 692/3282 [00:42<02:31, 17.12it/s]\u001b[A\n",
            "Epoch: 1:  21%|██        | 694/3282 [00:42<02:30, 17.20it/s]\u001b[A\n",
            "Epoch: 1:  21%|██        | 696/3282 [00:42<02:37, 16.46it/s]\u001b[A\n",
            "Epoch: 1:  21%|██▏       | 698/3282 [00:42<02:37, 16.44it/s]\u001b[A\n",
            "Epoch: 1:  21%|██▏       | 701/3282 [00:42<02:20, 18.38it/s]\u001b[A\n",
            "Epoch: 1:  21%|██▏       | 704/3282 [00:42<02:25, 17.76it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 706/3282 [00:42<02:31, 17.02it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 708/3282 [00:43<02:27, 17.47it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 710/3282 [00:43<02:38, 16.20it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 713/3282 [00:43<02:39, 16.12it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 717/3282 [00:43<02:26, 17.48it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 720/3282 [00:43<02:21, 18.12it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 722/3282 [00:43<02:19, 18.29it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1000 Task: frag Avg.Loss: 7.442190508299973e-06 Task Loss: 0.005358377005904913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  22%|██▏       | 724/3282 [00:43<02:29, 17.07it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 726/3282 [00:44<02:34, 16.53it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 729/3282 [00:44<02:43, 15.64it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 732/3282 [00:44<02:23, 17.79it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 734/3282 [00:44<02:33, 16.65it/s]\u001b[A\n",
            "Epoch: 1:  22%|██▏       | 737/3282 [00:44<02:42, 15.62it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 741/3282 [00:44<02:30, 16.91it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 744/3282 [00:45<02:21, 17.99it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 746/3282 [00:45<02:28, 17.09it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 749/3282 [00:45<02:39, 15.86it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 752/3282 [00:45<02:26, 17.26it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 754/3282 [00:45<02:25, 17.35it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 757/3282 [00:45<02:24, 17.49it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 760/3282 [00:45<02:07, 19.79it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 763/3282 [00:46<02:09, 19.48it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 766/3282 [00:46<02:17, 18.29it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 768/3282 [00:46<02:26, 17.19it/s]\u001b[A\n",
            "Epoch: 1:  23%|██▎       | 770/3282 [00:46<02:30, 16.70it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▎       | 772/3282 [00:46<02:24, 17.42it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▎       | 774/3282 [00:46<02:41, 15.55it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▎       | 776/3282 [00:46<02:36, 16.03it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▎       | 778/3282 [00:47<02:44, 15.27it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▍       | 780/3282 [00:47<02:35, 16.09it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▍       | 782/3282 [00:47<02:28, 16.81it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▍       | 784/3282 [00:47<02:31, 16.45it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▍       | 786/3282 [00:47<02:26, 17.04it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▍       | 788/3282 [00:47<02:24, 17.32it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▍       | 790/3282 [00:47<02:33, 16.19it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▍       | 793/3282 [00:48<02:30, 16.52it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▍       | 795/3282 [00:48<02:23, 17.31it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▍       | 797/3282 [00:48<02:28, 16.73it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▍       | 800/3282 [00:48<02:04, 20.01it/s]\u001b[A\n",
            "Epoch: 1:  24%|██▍       | 803/3282 [00:48<02:06, 19.63it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▍       | 806/3282 [00:48<02:26, 16.94it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▍       | 809/3282 [00:48<02:27, 16.78it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▍       | 812/3282 [00:49<02:12, 18.60it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▍       | 814/3282 [00:49<02:27, 16.78it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▍       | 817/3282 [00:49<02:32, 16.14it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▍       | 820/3282 [00:49<02:15, 18.19it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▌       | 822/3282 [00:49<02:17, 17.88it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▌       | 824/3282 [00:49<02:14, 18.26it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▌       | 826/3282 [00:49<02:26, 16.81it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▌       | 828/3282 [00:50<02:25, 16.85it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▌       | 830/3282 [00:50<02:26, 16.77it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▌       | 833/3282 [00:50<02:35, 15.80it/s]\u001b[A\n",
            "Epoch: 1:  25%|██▌       | 836/3282 [00:50<02:10, 18.72it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▌       | 838/3282 [00:50<02:29, 16.30it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▌       | 841/3282 [00:50<02:29, 16.31it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▌       | 844/3282 [00:50<02:07, 19.06it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▌       | 847/3282 [00:51<02:16, 17.89it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▌       | 849/3282 [00:51<02:37, 15.48it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▌       | 851/3282 [00:51<02:30, 16.15it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▌       | 853/3282 [00:51<02:25, 16.69it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▌       | 855/3282 [00:51<02:19, 17.43it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▌       | 857/3282 [00:51<02:23, 16.93it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▌       | 859/3282 [00:51<02:18, 17.48it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▌       | 861/3282 [00:51<02:16, 17.75it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▋       | 864/3282 [00:52<01:55, 20.85it/s]\u001b[A\n",
            "Epoch: 1:  26%|██▋       | 867/3282 [00:52<02:00, 20.00it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 870/3282 [00:52<02:02, 19.73it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 873/3282 [00:52<02:21, 16.98it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 876/3282 [00:52<02:09, 18.54it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 878/3282 [00:52<02:20, 17.14it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 881/3282 [00:53<02:27, 16.29it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 884/3282 [00:53<02:07, 18.81it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 887/3282 [00:53<02:13, 17.95it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 889/3282 [00:53<02:18, 17.29it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 892/3282 [00:53<02:10, 18.30it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 894/3282 [00:53<02:30, 15.87it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 897/3282 [00:54<02:37, 15.17it/s]\u001b[A\n",
            "Epoch: 1:  27%|██▋       | 900/3282 [00:54<02:27, 16.17it/s]\u001b[A\n",
            "Epoch: 1:  28%|██▊       | 903/3282 [00:54<02:16, 17.45it/s]\u001b[A\n",
            "Epoch: 1:  28%|██▊       | 905/3282 [00:54<02:20, 16.89it/s]\u001b[A\n",
            "Epoch: 1:  28%|██▊       | 908/3282 [00:54<02:11, 18.00it/s]\u001b[A\n",
            "Epoch: 1:  28%|██▊       | 910/3282 [00:54<02:25, 16.32it/s]\u001b[A\n",
            "Epoch: 1:  28%|██▊       | 913/3282 [00:54<02:23, 16.53it/s]\u001b[A\n",
            "Epoch: 1:  28%|██▊       | 917/3282 [00:55<02:19, 16.91it/s]\u001b[A\n",
            "Epoch: 1:  28%|██▊       | 920/3282 [00:55<02:21, 16.68it/s]\u001b[A\n",
            "Epoch: 1:  28%|██▊       | 922/3282 [00:55<02:17, 17.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1050 Task: intent Avg.Loss: 5.715386214433238e-05 Task Loss: 0.052581556141376495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  28%|██▊       | 925/3282 [00:55<02:24, 16.36it/s]\u001b[A\n",
            "Epoch: 1:  28%|██▊       | 928/3282 [00:55<02:03, 19.06it/s]\u001b[A\n",
            "Epoch: 1:  28%|██▊       | 931/3282 [00:55<02:13, 17.55it/s]\u001b[A\n",
            "Epoch: 1:  28%|██▊       | 933/3282 [00:56<02:22, 16.43it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▊       | 936/3282 [00:56<02:02, 19.08it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▊       | 939/3282 [00:56<02:11, 17.77it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▊       | 941/3282 [00:56<02:28, 15.74it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▊       | 943/3282 [00:56<02:20, 16.61it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▉       | 945/3282 [00:56<02:24, 16.13it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▉       | 947/3282 [00:56<02:20, 16.63it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▉       | 949/3282 [00:57<02:29, 15.56it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▉       | 951/3282 [00:57<02:21, 16.51it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▉       | 953/3282 [00:57<02:25, 16.02it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▉       | 956/3282 [00:57<02:02, 18.93it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▉       | 958/3282 [00:57<02:11, 17.62it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▉       | 961/3282 [00:57<02:13, 17.39it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▉       | 964/3282 [00:57<01:56, 19.95it/s]\u001b[A\n",
            "Epoch: 1:  29%|██▉       | 967/3282 [00:58<02:09, 17.83it/s]\u001b[A\n",
            "Epoch: 1:  30%|██▉       | 969/3282 [00:58<02:22, 16.23it/s]\u001b[A\n",
            "Epoch: 1:  30%|██▉       | 972/3282 [00:58<02:09, 17.88it/s]\u001b[A\n",
            "Epoch: 1:  30%|██▉       | 974/3282 [00:58<02:21, 16.36it/s]\u001b[A\n",
            "Epoch: 1:  30%|██▉       | 976/3282 [00:58<02:16, 16.91it/s]\u001b[A\n",
            "Epoch: 1:  30%|██▉       | 978/3282 [00:58<02:26, 15.73it/s]\u001b[A\n",
            "Epoch: 1:  30%|██▉       | 980/3282 [00:58<02:25, 15.84it/s]\u001b[A\n",
            "Epoch: 1:  30%|██▉       | 982/3282 [00:59<02:28, 15.53it/s]\u001b[A\n",
            "Epoch: 1:  30%|███       | 985/3282 [00:59<02:32, 15.05it/s]\u001b[A\n",
            "Epoch: 1:  30%|███       | 988/3282 [00:59<02:15, 16.98it/s]\u001b[A\n",
            "Epoch: 1:  30%|███       | 990/3282 [00:59<02:18, 16.57it/s]\u001b[A\n",
            "Epoch: 1:  30%|███       | 993/3282 [00:59<02:22, 16.05it/s]\u001b[A\n",
            "Epoch: 1:  30%|███       | 997/3282 [00:59<02:18, 16.52it/s]\u001b[A\n",
            "Epoch: 1:  30%|███       | 1000/3282 [01:00<02:05, 18.21it/s]\u001b[A\n",
            "Epoch: 1:  31%|███       | 1002/3282 [01:00<02:09, 17.59it/s]\u001b[A\n",
            "Epoch: 1:  31%|███       | 1005/3282 [01:00<02:15, 16.76it/s]\u001b[A\n",
            "Epoch: 1:  31%|███       | 1008/3282 [01:00<02:08, 17.64it/s]\u001b[A\n",
            "Epoch: 1:  31%|███       | 1010/3282 [01:00<02:14, 16.88it/s]\u001b[A\n",
            "Epoch: 1:  31%|███       | 1013/3282 [01:00<02:20, 16.19it/s]\u001b[A\n",
            "Epoch: 1:  31%|███       | 1016/3282 [01:00<02:00, 18.77it/s]\u001b[A\n",
            "Epoch: 1:  31%|███       | 1018/3282 [01:01<02:17, 16.49it/s]\u001b[A\n",
            "Epoch: 1:  31%|███       | 1021/3282 [01:01<02:19, 16.25it/s]\u001b[A\n",
            "Epoch: 1:  31%|███       | 1024/3282 [01:01<02:05, 18.02it/s]\u001b[A\n",
            "Epoch: 1:  31%|███▏      | 1026/3282 [01:01<02:16, 16.54it/s]\u001b[A\n",
            "Epoch: 1:  31%|███▏      | 1028/3282 [01:01<02:19, 16.13it/s]\u001b[A\n",
            "Epoch: 1:  31%|███▏      | 1030/3282 [01:01<02:15, 16.58it/s]\u001b[A\n",
            "Epoch: 1:  31%|███▏      | 1033/3282 [01:02<02:16, 16.51it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1036/3282 [01:02<02:03, 18.17it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1038/3282 [01:02<02:07, 17.54it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1041/3282 [01:02<02:03, 18.08it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1044/3282 [01:02<01:48, 20.64it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1047/3282 [01:02<01:49, 20.45it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1050/3282 [01:02<01:59, 18.61it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1052/3282 [01:02<01:58, 18.84it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1054/3282 [01:03<02:03, 18.00it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1057/3282 [01:03<02:01, 18.34it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1060/3282 [01:03<01:52, 19.79it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1063/3282 [01:03<01:51, 19.83it/s]\u001b[A\n",
            "Epoch: 1:  32%|███▏      | 1066/3282 [01:03<01:57, 18.79it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1068/3282 [01:03<01:56, 19.05it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1070/3282 [01:03<02:00, 18.31it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1072/3282 [01:04<02:05, 17.65it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1074/3282 [01:04<02:08, 17.14it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1077/3282 [01:04<02:17, 16.06it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1080/3282 [01:04<01:55, 19.06it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1083/3282 [01:04<01:56, 18.95it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1085/3282 [01:04<02:10, 16.90it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1088/3282 [01:04<02:03, 17.82it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1090/3282 [01:05<02:13, 16.45it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1093/3282 [01:05<02:16, 16.02it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1096/3282 [01:05<01:57, 18.57it/s]\u001b[A\n",
            "Epoch: 1:  33%|███▎      | 1098/3282 [01:05<02:01, 18.00it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▎      | 1101/3282 [01:05<02:07, 17.12it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▎      | 1104/3282 [01:05<01:55, 18.88it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▎      | 1106/3282 [01:05<01:54, 18.97it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▍      | 1109/3282 [01:06<01:59, 18.26it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▍      | 1111/3282 [01:06<01:56, 18.61it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▍      | 1113/3282 [01:06<02:14, 16.07it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▍      | 1116/3282 [01:06<02:01, 17.86it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▍      | 1118/3282 [01:06<02:09, 16.69it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▍      | 1120/3282 [01:06<02:17, 15.69it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▍      | 1122/3282 [01:06<02:12, 16.31it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1100 Task: NER Avg.Loss: 0.0002033203636528924 Task Loss: 0.2277188003063202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  34%|███▍      | 1124/3282 [01:07<02:07, 16.86it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▍      | 1126/3282 [01:07<02:20, 15.38it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▍      | 1129/3282 [01:07<02:11, 16.36it/s]\u001b[A\n",
            "Epoch: 1:  34%|███▍      | 1132/3282 [01:07<02:03, 17.35it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▍      | 1134/3282 [01:07<02:01, 17.64it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▍      | 1137/3282 [01:07<02:10, 16.42it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▍      | 1140/3282 [01:07<01:59, 17.93it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▍      | 1142/3282 [01:08<02:08, 16.63it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▍      | 1145/3282 [01:08<02:11, 16.19it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▍      | 1147/3282 [01:08<02:07, 16.77it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▌      | 1149/3282 [01:08<02:19, 15.25it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▌      | 1152/3282 [01:08<02:02, 17.36it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▌      | 1154/3282 [01:08<02:11, 16.21it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▌      | 1157/3282 [01:09<02:06, 16.84it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▌      | 1160/3282 [01:09<01:47, 19.73it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▌      | 1163/3282 [01:09<01:54, 18.58it/s]\u001b[A\n",
            "Epoch: 1:  35%|███▌      | 1165/3282 [01:09<02:15, 15.66it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▌      | 1168/3282 [01:09<02:04, 17.00it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▌      | 1170/3282 [01:09<02:16, 15.47it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▌      | 1172/3282 [01:09<02:09, 16.25it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▌      | 1174/3282 [01:10<02:08, 16.38it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▌      | 1176/3282 [01:10<02:02, 17.19it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▌      | 1178/3282 [01:10<02:12, 15.83it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▌      | 1181/3282 [01:10<02:15, 15.55it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▌      | 1184/3282 [01:10<02:11, 15.93it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▌      | 1186/3282 [01:10<02:14, 15.59it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▌      | 1189/3282 [01:10<02:08, 16.28it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▋      | 1192/3282 [01:11<01:59, 17.50it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▋      | 1194/3282 [01:11<01:59, 17.46it/s]\u001b[A\n",
            "Epoch: 1:  36%|███▋      | 1196/3282 [01:11<01:57, 17.68it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1198/3282 [01:11<02:12, 15.74it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1200/3282 [01:11<02:10, 16.00it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1202/3282 [01:11<02:19, 14.95it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1205/3282 [01:12<02:17, 15.15it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1208/3282 [01:12<02:01, 17.00it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1210/3282 [01:12<02:04, 16.59it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1212/3282 [01:12<01:59, 17.37it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1215/3282 [01:12<01:46, 19.35it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1217/3282 [01:12<01:57, 17.52it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1220/3282 [01:12<01:47, 19.16it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1222/3282 [01:12<01:51, 18.45it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1224/3282 [01:13<02:05, 16.44it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1226/3282 [01:13<02:10, 15.77it/s]\u001b[A\n",
            "Epoch: 1:  37%|███▋      | 1229/3282 [01:13<02:16, 15.09it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1232/3282 [01:13<01:58, 17.27it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1234/3282 [01:13<02:09, 15.85it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1237/3282 [01:13<02:11, 15.50it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1240/3282 [01:14<01:57, 17.31it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1242/3282 [01:14<01:58, 17.25it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1244/3282 [01:14<01:56, 17.55it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1246/3282 [01:14<02:00, 16.92it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1249/3282 [01:14<02:02, 16.56it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1252/3282 [01:14<01:51, 18.15it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1254/3282 [01:14<01:56, 17.37it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1257/3282 [01:15<01:57, 17.21it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1261/3282 [01:15<01:47, 18.88it/s]\u001b[A\n",
            "Epoch: 1:  38%|███▊      | 1263/3282 [01:15<01:46, 18.94it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▊      | 1265/3282 [01:15<01:57, 17.11it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▊      | 1268/3282 [01:15<01:46, 18.98it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▊      | 1270/3282 [01:15<02:07, 15.73it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▉      | 1273/3282 [01:15<02:14, 14.98it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▉      | 1276/3282 [01:16<01:58, 16.99it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▉      | 1278/3282 [01:16<02:13, 14.99it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▉      | 1281/3282 [01:16<02:12, 15.11it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▉      | 1283/3282 [01:16<02:04, 16.00it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▉      | 1285/3282 [01:16<02:17, 14.48it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▉      | 1288/3282 [01:16<01:54, 17.35it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▉      | 1290/3282 [01:17<02:13, 14.97it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▉      | 1293/3282 [01:17<02:12, 15.02it/s]\u001b[A\n",
            "Epoch: 1:  39%|███▉      | 1295/3282 [01:17<02:06, 15.68it/s]\u001b[A\n",
            "Epoch: 1:  40%|███▉      | 1297/3282 [01:17<02:19, 14.25it/s]\u001b[A\n",
            "Epoch: 1:  40%|███▉      | 1300/3282 [01:17<01:59, 16.61it/s]\u001b[A\n",
            "Epoch: 1:  40%|███▉      | 1302/3282 [01:17<02:00, 16.43it/s]\u001b[A\n",
            "Epoch: 1:  40%|███▉      | 1305/3282 [01:17<01:58, 16.67it/s]\u001b[A\n",
            "Epoch: 1:  40%|███▉      | 1308/3282 [01:18<01:49, 18.10it/s]\u001b[A\n",
            "Epoch: 1:  40%|███▉      | 1310/3282 [01:18<01:58, 16.60it/s]\u001b[A\n",
            "Epoch: 1:  40%|███▉      | 1312/3282 [01:18<01:54, 17.17it/s]\u001b[A\n",
            "Epoch: 1:  40%|████      | 1314/3282 [01:18<01:57, 16.70it/s]\u001b[A\n",
            "Epoch: 1:  40%|████      | 1317/3282 [01:18<01:43, 18.91it/s]\u001b[A\n",
            "Epoch: 1:  40%|████      | 1319/3282 [01:18<01:46, 18.41it/s]\u001b[A\n",
            "Epoch: 1:  40%|████      | 1321/3282 [01:18<02:02, 15.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1150 Task: intent Avg.Loss: 2.197891444666311e-05 Task Loss: 0.0290121678262949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  40%|████      | 1324/3282 [01:19<01:50, 17.71it/s]\u001b[A\n",
            "Epoch: 1:  40%|████      | 1326/3282 [01:19<02:06, 15.48it/s]\u001b[A\n",
            "Epoch: 1:  40%|████      | 1329/3282 [01:19<01:57, 16.67it/s]\u001b[A\n",
            "Epoch: 1:  41%|████      | 1332/3282 [01:19<01:40, 19.33it/s]\u001b[A\n",
            "Epoch: 1:  41%|████      | 1335/3282 [01:19<01:42, 18.99it/s]\u001b[A\n",
            "Epoch: 1:  41%|████      | 1337/3282 [01:19<01:51, 17.48it/s]\u001b[A\n",
            "Epoch: 1:  41%|████      | 1340/3282 [01:19<01:46, 18.25it/s]\u001b[A\n",
            "Epoch: 1:  41%|████      | 1342/3282 [01:20<01:56, 16.66it/s]\u001b[A\n",
            "Epoch: 1:  41%|████      | 1345/3282 [01:20<01:57, 16.53it/s]\u001b[A\n",
            "Epoch: 1:  41%|████      | 1347/3282 [01:20<01:54, 16.93it/s]\u001b[A\n",
            "Epoch: 1:  41%|████      | 1349/3282 [01:20<02:03, 15.59it/s]\u001b[A\n",
            "Epoch: 1:  41%|████      | 1352/3282 [01:20<01:50, 17.47it/s]\u001b[A\n",
            "Epoch: 1:  41%|████▏     | 1354/3282 [01:20<01:56, 16.58it/s]\u001b[A\n",
            "Epoch: 1:  41%|████▏     | 1357/3282 [01:21<01:59, 16.13it/s]\u001b[A\n",
            "Epoch: 1:  41%|████▏     | 1360/3282 [01:21<01:46, 18.08it/s]\u001b[A\n",
            "Epoch: 1:  41%|████▏     | 1362/3282 [01:21<01:50, 17.35it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1364/3282 [01:21<01:48, 17.68it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1366/3282 [01:21<01:51, 17.20it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1369/3282 [01:21<01:59, 15.97it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1371/3282 [01:21<01:53, 16.79it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1373/3282 [01:21<02:05, 15.16it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1376/3282 [01:22<01:49, 17.34it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1378/3282 [01:22<01:52, 16.87it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1381/3282 [01:22<01:53, 16.81it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1384/3282 [01:22<01:52, 16.90it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1386/3282 [01:22<01:58, 16.05it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1389/3282 [01:22<02:01, 15.62it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1392/3282 [01:23<01:49, 17.31it/s]\u001b[A\n",
            "Epoch: 1:  42%|████▏     | 1394/3282 [01:23<01:55, 16.30it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1396/3282 [01:23<01:51, 16.99it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1398/3282 [01:23<01:57, 16.06it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1400/3282 [01:23<01:51, 16.91it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1402/3282 [01:23<01:54, 16.38it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1404/3282 [01:23<01:50, 16.92it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1406/3282 [01:23<01:52, 16.63it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1408/3282 [01:24<01:51, 16.83it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1410/3282 [01:24<02:00, 15.56it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1412/3282 [01:24<01:55, 16.20it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1414/3282 [01:24<01:59, 15.59it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1417/3282 [01:24<02:02, 15.18it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1420/3282 [01:24<01:48, 17.12it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1422/3282 [01:24<01:59, 15.52it/s]\u001b[A\n",
            "Epoch: 1:  43%|████▎     | 1425/3282 [01:25<01:59, 15.54it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▎     | 1428/3282 [01:25<01:49, 16.88it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▎     | 1430/3282 [01:25<01:50, 16.77it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▎     | 1433/3282 [01:25<01:56, 15.90it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1436/3282 [01:25<01:45, 17.49it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1438/3282 [01:25<01:46, 17.36it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1440/3282 [01:25<01:43, 17.82it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1442/3282 [01:26<01:44, 17.66it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1445/3282 [01:26<01:42, 17.84it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1448/3282 [01:26<01:34, 19.48it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1450/3282 [01:26<01:42, 17.96it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1452/3282 [01:26<01:41, 18.03it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1454/3282 [01:26<01:47, 17.07it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1456/3282 [01:26<01:47, 17.01it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1458/3282 [01:27<01:50, 16.52it/s]\u001b[A\n",
            "Epoch: 1:  44%|████▍     | 1460/3282 [01:27<01:45, 17.34it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▍     | 1462/3282 [01:27<01:56, 15.65it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▍     | 1464/3282 [01:27<01:49, 16.63it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▍     | 1466/3282 [01:27<01:52, 16.13it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▍     | 1468/3282 [01:27<01:54, 15.81it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▍     | 1470/3282 [01:27<01:57, 15.46it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▍     | 1473/3282 [01:27<01:52, 16.10it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▍     | 1476/3282 [01:28<01:37, 18.47it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▌     | 1478/3282 [01:28<01:39, 18.11it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▌     | 1481/3282 [01:28<01:34, 19.02it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▌     | 1485/3282 [01:28<01:36, 18.58it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▌     | 1488/3282 [01:28<01:29, 20.05it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▌     | 1491/3282 [01:28<01:39, 17.95it/s]\u001b[A\n",
            "Epoch: 1:  45%|████▌     | 1493/3282 [01:29<01:58, 15.05it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▌     | 1496/3282 [01:29<01:45, 16.94it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▌     | 1498/3282 [01:29<01:46, 16.73it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▌     | 1501/3282 [01:29<01:38, 18.16it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▌     | 1504/3282 [01:29<01:37, 18.25it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▌     | 1506/3282 [01:29<01:43, 17.20it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▌     | 1508/3282 [01:29<01:43, 17.10it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▌     | 1510/3282 [01:30<01:52, 15.75it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▌     | 1512/3282 [01:30<01:57, 15.05it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▌     | 1515/3282 [01:30<01:45, 16.80it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▌     | 1517/3282 [01:30<01:54, 15.42it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▋     | 1520/3282 [01:30<01:54, 15.36it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▋     | 1522/3282 [01:30<01:50, 15.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1200 Task: NER Avg.Loss: 9.440496796742082e-05 Task Loss: 0.14349554479122162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  46%|████▋     | 1524/3282 [01:30<01:50, 15.86it/s]\u001b[A\n",
            "Epoch: 1:  46%|████▋     | 1526/3282 [01:31<01:47, 16.29it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1529/3282 [01:31<01:55, 15.16it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1531/3282 [01:31<01:50, 15.88it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1533/3282 [01:31<01:57, 14.91it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1536/3282 [01:31<01:41, 17.21it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1538/3282 [01:31<01:42, 17.04it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1541/3282 [01:31<01:43, 16.77it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1544/3282 [01:32<01:28, 19.60it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1547/3282 [01:32<01:38, 17.59it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1549/3282 [01:32<01:41, 16.99it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1552/3282 [01:32<01:27, 19.88it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1555/3282 [01:32<01:32, 18.72it/s]\u001b[A\n",
            "Epoch: 1:  47%|████▋     | 1558/3282 [01:32<01:42, 16.90it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1561/3282 [01:33<01:43, 16.62it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1563/3282 [01:33<01:39, 17.21it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1565/3282 [01:33<01:51, 15.38it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1568/3282 [01:33<01:33, 18.35it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1571/3282 [01:33<01:38, 17.33it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1573/3282 [01:33<01:52, 15.25it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1575/3282 [01:33<01:47, 15.94it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1577/3282 [01:34<01:48, 15.73it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1580/3282 [01:34<01:40, 16.97it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1582/3282 [01:34<01:48, 15.71it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1585/3282 [01:34<01:46, 15.92it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1588/3282 [01:34<01:29, 18.84it/s]\u001b[A\n",
            "Epoch: 1:  48%|████▊     | 1591/3282 [01:34<01:37, 17.40it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▊     | 1593/3282 [01:35<01:41, 16.61it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▊     | 1596/3282 [01:35<01:32, 18.21it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▊     | 1598/3282 [01:35<01:38, 17.01it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▉     | 1600/3282 [01:35<01:35, 17.58it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▉     | 1602/3282 [01:35<01:38, 17.00it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▉     | 1604/3282 [01:35<01:42, 16.37it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▉     | 1606/3282 [01:35<01:50, 15.12it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▉     | 1608/3282 [01:35<01:45, 15.87it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▉     | 1610/3282 [01:36<01:54, 14.66it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▉     | 1613/3282 [01:36<01:41, 16.52it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▉     | 1617/3282 [01:36<01:38, 16.91it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▉     | 1620/3282 [01:36<01:30, 18.46it/s]\u001b[A\n",
            "Epoch: 1:  49%|████▉     | 1622/3282 [01:36<01:29, 18.52it/s]\u001b[A\n",
            "Epoch: 1:  50%|████▉     | 1625/3282 [01:36<01:35, 17.39it/s]\u001b[A\n",
            "Epoch: 1:  50%|████▉     | 1628/3282 [01:37<01:31, 18.01it/s]\u001b[A\n",
            "Epoch: 1:  50%|████▉     | 1630/3282 [01:37<01:38, 16.79it/s]\u001b[A\n",
            "Epoch: 1:  50%|████▉     | 1632/3282 [01:37<01:40, 16.35it/s]\u001b[A\n",
            "Epoch: 1:  50%|████▉     | 1634/3282 [01:37<01:43, 15.99it/s]\u001b[A\n",
            "Epoch: 1:  50%|████▉     | 1637/3282 [01:37<01:40, 16.33it/s]\u001b[A\n",
            "Epoch: 1:  50%|████▉     | 1640/3282 [01:37<01:39, 16.45it/s]\u001b[A\n",
            "Epoch: 1:  50%|█████     | 1642/3282 [01:37<01:42, 16.06it/s]\u001b[A\n",
            "Epoch: 1:  50%|█████     | 1644/3282 [01:38<01:43, 15.81it/s]\u001b[A\n",
            "Epoch: 1:  50%|█████     | 1646/3282 [01:38<01:44, 15.65it/s]\u001b[A\n",
            "Epoch: 1:  50%|█████     | 1649/3282 [01:38<01:46, 15.40it/s]\u001b[A\n",
            "Epoch: 1:  50%|█████     | 1652/3282 [01:38<01:32, 17.68it/s]\u001b[A\n",
            "Epoch: 1:  50%|█████     | 1654/3282 [01:38<01:36, 16.86it/s]\u001b[A\n",
            "Epoch: 1:  50%|█████     | 1657/3282 [01:38<01:41, 16.01it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████     | 1661/3282 [01:39<01:27, 18.47it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████     | 1664/3282 [01:39<01:18, 20.71it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████     | 1667/3282 [01:39<01:17, 20.78it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████     | 1670/3282 [01:39<01:28, 18.26it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████     | 1672/3282 [01:39<01:30, 17.72it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████     | 1674/3282 [01:39<01:34, 17.02it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████     | 1677/3282 [01:39<01:42, 15.67it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████     | 1679/3282 [01:40<01:37, 16.49it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████     | 1681/3282 [01:40<01:37, 16.37it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████▏    | 1684/3282 [01:40<01:25, 18.60it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████▏    | 1686/3282 [01:40<01:44, 15.31it/s]\u001b[A\n",
            "Epoch: 1:  51%|█████▏    | 1689/3282 [01:40<01:35, 16.74it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1692/3282 [01:40<01:27, 18.08it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1694/3282 [01:40<01:37, 16.33it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1696/3282 [01:41<01:35, 16.60it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1698/3282 [01:41<01:37, 16.25it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1700/3282 [01:41<01:36, 16.36it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1702/3282 [01:41<01:39, 15.95it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1705/3282 [01:41<01:36, 16.30it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1708/3282 [01:41<01:25, 18.35it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1710/3282 [01:41<01:31, 17.14it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1712/3282 [01:42<01:35, 16.40it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1714/3282 [01:42<01:38, 15.92it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1717/3282 [01:42<01:36, 16.19it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1720/3282 [01:42<01:27, 17.92it/s]\u001b[A\n",
            "Epoch: 1:  52%|█████▏    | 1722/3282 [01:42<01:26, 17.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1250 Task: intent Avg.Loss: 3.935663244192256e-06 Task Loss: 0.006769340485334396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  53%|█████▎    | 1724/3282 [01:42<01:28, 17.53it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1726/3282 [01:42<01:33, 16.70it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1729/3282 [01:43<01:36, 16.11it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1732/3282 [01:43<01:24, 18.29it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1734/3282 [01:43<01:33, 16.51it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1736/3282 [01:43<01:31, 16.86it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1738/3282 [01:43<01:38, 15.64it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1740/3282 [01:43<01:39, 15.51it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1742/3282 [01:43<01:48, 14.21it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1745/3282 [01:44<01:46, 14.47it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1749/3282 [01:44<01:37, 15.76it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1752/3282 [01:44<01:23, 18.32it/s]\u001b[A\n",
            "Epoch: 1:  53%|█████▎    | 1754/3282 [01:44<01:35, 16.00it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▎    | 1757/3282 [01:44<01:25, 17.86it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▎    | 1760/3282 [01:44<01:21, 18.74it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▎    | 1762/3282 [01:45<01:24, 18.06it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▎    | 1764/3282 [01:45<01:27, 17.43it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▍    | 1766/3282 [01:45<01:35, 15.81it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▍    | 1769/3282 [01:45<01:37, 15.49it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▍    | 1772/3282 [01:45<01:21, 18.43it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▍    | 1774/3282 [01:45<01:29, 16.86it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▍    | 1777/3282 [01:45<01:33, 16.17it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▍    | 1780/3282 [01:46<01:19, 18.95it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▍    | 1783/3282 [01:46<01:19, 18.95it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▍    | 1786/3282 [01:46<01:19, 18.91it/s]\u001b[A\n",
            "Epoch: 1:  54%|█████▍    | 1788/3282 [01:46<01:19, 18.71it/s]\u001b[A\n",
            "Epoch: 1:  55%|█████▍    | 1790/3282 [01:46<01:25, 17.50it/s]\u001b[A\n",
            "Epoch: 1:  55%|█████▍    | 1793/3282 [01:46<01:22, 17.98it/s]\u001b[A\n",
            "Epoch: 1:  55%|█████▍    | 1797/3282 [01:47<01:24, 17.67it/s]\u001b[A\n",
            "Epoch: 1:  55%|█████▍    | 1800/3282 [01:47<01:14, 19.79it/s]\u001b[A\n",
            "Epoch: 1:  55%|█████▍    | 1803/3282 [01:47<01:22, 17.88it/s]\u001b[A\n",
            "Epoch: 1:  55%|█████▍    | 1805/3282 [01:47<01:37, 15.14it/s]\u001b[A\n",
            "Epoch: 1:  55%|█████▌    | 1808/3282 [01:47<01:35, 15.36it/s]\u001b[A\n",
            "Epoch: 1:  55%|█████▌    | 1810/3282 [01:47<01:31, 16.10it/s]\u001b[A\n",
            "Epoch: 1:  55%|█████▌    | 1813/3282 [01:48<01:32, 15.96it/s]\u001b[A\n",
            "Epoch: 1:  55%|█████▌    | 1816/3282 [01:48<01:18, 18.71it/s]\u001b[A\n",
            "Epoch: 1:  55%|█████▌    | 1819/3282 [01:48<01:14, 19.57it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1822/3282 [01:48<01:24, 17.27it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1824/3282 [01:48<01:25, 17.09it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1826/3282 [01:48<01:33, 15.63it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1828/3282 [01:48<01:27, 16.54it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1830/3282 [01:48<01:29, 16.27it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1832/3282 [01:49<01:26, 16.83it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1834/3282 [01:49<01:32, 15.62it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1837/3282 [01:49<01:37, 14.90it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1840/3282 [01:49<01:28, 16.27it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1842/3282 [01:49<01:30, 15.98it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1844/3282 [01:49<01:31, 15.70it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▌    | 1846/3282 [01:50<01:29, 15.98it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▋    | 1849/3282 [01:50<01:24, 17.05it/s]\u001b[A\n",
            "Epoch: 1:  56%|█████▋    | 1852/3282 [01:50<01:12, 19.74it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1855/3282 [01:50<01:14, 19.04it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1857/3282 [01:50<01:22, 17.18it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1860/3282 [01:50<01:11, 19.89it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1863/3282 [01:50<01:16, 18.67it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1865/3282 [01:51<01:22, 17.10it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1868/3282 [01:51<01:16, 18.37it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1870/3282 [01:51<01:32, 15.34it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1872/3282 [01:51<01:27, 16.19it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1874/3282 [01:51<01:32, 15.19it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1877/3282 [01:51<01:31, 15.29it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1880/3282 [01:51<01:23, 16.88it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1882/3282 [01:52<01:25, 16.30it/s]\u001b[A\n",
            "Epoch: 1:  57%|█████▋    | 1885/3282 [01:52<01:20, 17.37it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1888/3282 [01:52<01:14, 18.81it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1890/3282 [01:52<01:17, 17.89it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1893/3282 [01:52<01:20, 17.17it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1895/3282 [01:52<01:19, 17.42it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1897/3282 [01:52<01:23, 16.57it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1900/3282 [01:53<01:14, 18.58it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1902/3282 [01:53<01:20, 17.11it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1905/3282 [01:53<01:26, 15.84it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1908/3282 [01:53<01:19, 17.28it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1910/3282 [01:53<01:29, 15.36it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1913/3282 [01:53<01:23, 16.33it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1915/3282 [01:54<01:20, 17.08it/s]\u001b[A\n",
            "Epoch: 1:  58%|█████▊    | 1917/3282 [01:54<01:24, 16.16it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▊    | 1920/3282 [01:54<01:23, 16.22it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▊    | 1922/3282 [01:54<01:31, 14.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1300 Task: frag Avg.Loss: 1.4401323369384045e-06 Task Loss: 0.0027650538831949234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  59%|█████▊    | 1924/3282 [01:54<01:27, 15.59it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▊    | 1926/3282 [01:54<01:29, 15.22it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▊    | 1928/3282 [01:54<01:23, 16.15it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▉    | 1930/3282 [01:54<01:26, 15.54it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▉    | 1932/3282 [01:55<01:22, 16.44it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▉    | 1934/3282 [01:55<01:23, 16.12it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▉    | 1936/3282 [01:55<01:22, 16.26it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▉    | 1938/3282 [01:55<01:32, 14.48it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▉    | 1941/3282 [01:55<01:26, 15.48it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▉    | 1944/3282 [01:55<01:12, 18.55it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▉    | 1946/3282 [01:55<01:22, 16.27it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▉    | 1949/3282 [01:56<01:27, 15.22it/s]\u001b[A\n",
            "Epoch: 1:  59%|█████▉    | 1951/3282 [01:56<01:22, 16.10it/s]\u001b[A\n",
            "Epoch: 1:  60%|█████▉    | 1953/3282 [01:56<01:27, 15.17it/s]\u001b[A\n",
            "Epoch: 1:  60%|█████▉    | 1955/3282 [01:56<01:21, 16.24it/s]\u001b[A\n",
            "Epoch: 1:  60%|█████▉    | 1957/3282 [01:56<01:23, 15.78it/s]\u001b[A\n",
            "Epoch: 1:  60%|█████▉    | 1960/3282 [01:56<01:12, 18.14it/s]\u001b[A\n",
            "Epoch: 1:  60%|█████▉    | 1962/3282 [01:56<01:11, 18.43it/s]\u001b[A\n",
            "Epoch: 1:  60%|█████▉    | 1965/3282 [01:57<01:15, 17.50it/s]\u001b[A\n",
            "Epoch: 1:  60%|█████▉    | 1968/3282 [01:57<01:05, 19.94it/s]\u001b[A\n",
            "Epoch: 1:  60%|██████    | 1971/3282 [01:57<01:09, 18.80it/s]\u001b[A\n",
            "Epoch: 1:  60%|██████    | 1973/3282 [01:57<01:17, 16.80it/s]\u001b[A\n",
            "Epoch: 1:  60%|██████    | 1976/3282 [01:57<01:08, 19.14it/s]\u001b[A\n",
            "Epoch: 1:  60%|██████    | 1979/3282 [01:57<01:12, 17.85it/s]\u001b[A\n",
            "Epoch: 1:  60%|██████    | 1981/3282 [01:58<01:20, 16.22it/s]\u001b[A\n",
            "Epoch: 1:  60%|██████    | 1984/3282 [01:58<01:16, 17.01it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 1986/3282 [01:58<01:14, 17.48it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 1988/3282 [01:58<01:15, 17.10it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 1990/3282 [01:58<01:14, 17.45it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 1993/3282 [01:58<01:21, 15.76it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 1996/3282 [01:58<01:09, 18.50it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 1998/3282 [01:58<01:16, 16.83it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 2000/3282 [01:59<01:15, 17.06it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 2002/3282 [01:59<01:16, 16.71it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 2004/3282 [01:59<01:13, 17.46it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 2006/3282 [01:59<01:24, 15.04it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 2008/3282 [01:59<01:25, 14.96it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████    | 2010/3282 [01:59<01:26, 14.64it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████▏   | 2013/3282 [02:00<01:30, 13.98it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████▏   | 2016/3282 [02:00<01:15, 16.85it/s]\u001b[A\n",
            "Epoch: 1:  61%|██████▏   | 2018/3282 [02:00<01:22, 15.24it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2021/3282 [02:00<01:20, 15.67it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2024/3282 [02:00<01:07, 18.63it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2027/3282 [02:00<01:11, 17.61it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2029/3282 [02:00<01:16, 16.35it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2032/3282 [02:01<01:04, 19.27it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2035/3282 [02:01<01:14, 16.71it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2037/3282 [02:01<01:23, 14.99it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2040/3282 [02:01<01:19, 15.55it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2042/3282 [02:01<01:20, 15.34it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2045/3282 [02:01<01:22, 14.91it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2047/3282 [02:02<01:17, 15.90it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2049/3282 [02:02<01:17, 15.99it/s]\u001b[A\n",
            "Epoch: 1:  62%|██████▏   | 2051/3282 [02:02<01:13, 16.73it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2053/3282 [02:02<01:19, 15.40it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2056/3282 [02:02<01:11, 17.03it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2058/3282 [02:02<01:15, 16.16it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2061/3282 [02:02<01:12, 16.74it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2064/3282 [02:03<01:10, 17.39it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2066/3282 [02:03<01:08, 17.72it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2069/3282 [02:03<01:08, 17.70it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2072/3282 [02:03<01:05, 18.35it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2074/3282 [02:03<01:05, 18.42it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2077/3282 [02:03<01:08, 17.59it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2080/3282 [02:03<01:03, 19.01it/s]\u001b[A\n",
            "Epoch: 1:  63%|██████▎   | 2082/3282 [02:04<01:09, 17.35it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▎   | 2085/3282 [02:04<01:11, 16.72it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▎   | 2088/3282 [02:04<01:06, 17.91it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▎   | 2090/3282 [02:04<01:12, 16.45it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▎   | 2092/3282 [02:04<01:12, 16.48it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▍   | 2094/3282 [02:04<01:16, 15.56it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▍   | 2096/3282 [02:04<01:17, 15.32it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▍   | 2098/3282 [02:05<01:19, 14.86it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▍   | 2101/3282 [02:05<01:15, 15.72it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▍   | 2104/3282 [02:05<01:12, 16.33it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▍   | 2106/3282 [02:05<01:14, 15.72it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▍   | 2109/3282 [02:05<01:11, 16.35it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▍   | 2112/3282 [02:05<01:03, 18.42it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▍   | 2114/3282 [02:05<01:06, 17.51it/s]\u001b[A\n",
            "Epoch: 1:  64%|██████▍   | 2116/3282 [02:06<01:08, 16.92it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▍   | 2118/3282 [02:06<01:06, 17.40it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▍   | 2120/3282 [02:06<01:06, 17.57it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▍   | 2122/3282 [02:06<01:05, 17.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1350 Task: frag Avg.Loss: 5.641915095111472e-07 Task Loss: 0.0011960859410464764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  65%|██████▍   | 2124/3282 [02:06<01:05, 17.65it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▍   | 2126/3282 [02:06<01:08, 16.79it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▍   | 2128/3282 [02:06<01:07, 17.12it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▍   | 2130/3282 [02:06<01:11, 16.01it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▍   | 2133/3282 [02:07<01:19, 14.41it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▌   | 2136/3282 [02:07<01:05, 17.47it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▌   | 2138/3282 [02:07<01:05, 17.48it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▌   | 2141/3282 [02:07<01:00, 18.92it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▌   | 2144/3282 [02:07<00:53, 21.23it/s]\u001b[A\n",
            "Epoch: 1:  65%|██████▌   | 2147/3282 [02:07<01:00, 18.76it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▌   | 2150/3282 [02:08<01:01, 18.47it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▌   | 2153/3282 [02:08<01:03, 17.69it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▌   | 2156/3282 [02:08<00:55, 20.11it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▌   | 2159/3282 [02:08<00:56, 19.99it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▌   | 2162/3282 [02:08<01:04, 17.33it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▌   | 2164/3282 [02:08<01:05, 17.00it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▌   | 2166/3282 [02:08<01:04, 17.31it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▌   | 2168/3282 [02:09<01:03, 17.62it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▌   | 2170/3282 [02:09<01:04, 17.17it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▌   | 2173/3282 [02:09<01:10, 15.63it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▋   | 2176/3282 [02:09<01:01, 17.98it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▋   | 2178/3282 [02:09<01:10, 15.65it/s]\u001b[A\n",
            "Epoch: 1:  66%|██████▋   | 2181/3282 [02:09<01:10, 15.60it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2184/3282 [02:10<01:04, 16.96it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2186/3282 [02:10<01:04, 16.96it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2189/3282 [02:10<01:06, 16.44it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2193/3282 [02:10<01:02, 17.50it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2196/3282 [02:10<00:59, 18.37it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2198/3282 [02:10<01:04, 16.71it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2201/3282 [02:11<01:05, 16.49it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2204/3282 [02:11<00:57, 18.90it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2206/3282 [02:11<00:59, 17.94it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2209/3282 [02:11<01:03, 16.90it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2212/3282 [02:11<00:57, 18.77it/s]\u001b[A\n",
            "Epoch: 1:  67%|██████▋   | 2214/3282 [02:11<00:57, 18.63it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2217/3282 [02:11<01:01, 17.44it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2220/3282 [02:12<00:55, 19.09it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2222/3282 [02:12<00:58, 18.12it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2224/3282 [02:12<00:57, 18.36it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2226/3282 [02:12<01:02, 16.98it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2228/3282 [02:12<01:03, 16.51it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2230/3282 [02:12<01:06, 15.93it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2233/3282 [02:12<01:07, 15.59it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2236/3282 [02:12<00:59, 17.45it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2238/3282 [02:13<01:01, 16.85it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2241/3282 [02:13<00:57, 17.99it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2243/3282 [02:13<01:00, 17.27it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2245/3282 [02:13<01:07, 15.45it/s]\u001b[A\n",
            "Epoch: 1:  68%|██████▊   | 2248/3282 [02:13<01:01, 16.89it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▊   | 2250/3282 [02:13<01:06, 15.45it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▊   | 2252/3282 [02:13<01:03, 16.13it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▊   | 2254/3282 [02:14<01:07, 15.14it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▊   | 2256/3282 [02:14<01:03, 16.14it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▉   | 2258/3282 [02:14<01:02, 16.45it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▉   | 2261/3282 [02:14<01:04, 15.73it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▉   | 2264/3282 [02:14<00:55, 18.32it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▉   | 2266/3282 [02:14<00:57, 17.67it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▉   | 2268/3282 [02:14<00:56, 17.99it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▉   | 2270/3282 [02:15<00:55, 18.40it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▉   | 2272/3282 [02:15<01:00, 16.80it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▉   | 2274/3282 [02:15<01:01, 16.29it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▉   | 2277/3282 [02:15<00:59, 16.81it/s]\u001b[A\n",
            "Epoch: 1:  69%|██████▉   | 2279/3282 [02:15<00:59, 16.91it/s]\u001b[A\n",
            "Epoch: 1:  70%|██████▉   | 2281/3282 [02:15<01:04, 15.52it/s]\u001b[A\n",
            "Epoch: 1:  70%|██████▉   | 2284/3282 [02:15<00:57, 17.43it/s]\u001b[A\n",
            "Epoch: 1:  70%|██████▉   | 2286/3282 [02:15<00:59, 16.86it/s]\u001b[A\n",
            "Epoch: 1:  70%|██████▉   | 2289/3282 [02:16<01:01, 16.19it/s]\u001b[A\n",
            "Epoch: 1:  70%|██████▉   | 2293/3282 [02:16<00:56, 17.35it/s]\u001b[A\n",
            "Epoch: 1:  70%|██████▉   | 2296/3282 [02:16<00:50, 19.43it/s]\u001b[A\n",
            "Epoch: 1:  70%|███████   | 2299/3282 [02:16<00:55, 17.78it/s]\u001b[A\n",
            "Epoch: 1:  70%|███████   | 2301/3282 [02:16<01:01, 15.93it/s]\u001b[A\n",
            "Epoch: 1:  70%|███████   | 2303/3282 [02:16<01:00, 16.14it/s]\u001b[A\n",
            "Epoch: 1:  70%|███████   | 2305/3282 [02:17<01:03, 15.39it/s]\u001b[A\n",
            "Epoch: 1:  70%|███████   | 2308/3282 [02:17<00:59, 16.40it/s]\u001b[A\n",
            "Epoch: 1:  70%|███████   | 2310/3282 [02:17<00:59, 16.33it/s]\u001b[A\n",
            "Epoch: 1:  70%|███████   | 2313/3282 [02:17<01:03, 15.18it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████   | 2317/3282 [02:17<00:56, 17.06it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████   | 2320/3282 [02:18<00:56, 17.07it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████   | 2322/3282 [02:18<00:56, 16.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1400 Task: intent Avg.Loss: 2.0906668396492023e-06 Task Loss: 0.004850347060710192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  71%|███████   | 2324/3282 [02:18<00:54, 17.53it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████   | 2326/3282 [02:18<00:55, 17.08it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████   | 2328/3282 [02:18<00:58, 16.42it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████   | 2330/3282 [02:18<01:02, 15.33it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████   | 2333/3282 [02:18<01:04, 14.76it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████   | 2335/3282 [02:18<01:00, 15.70it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████   | 2337/3282 [02:19<01:03, 14.93it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████▏  | 2340/3282 [02:19<00:59, 15.87it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████▏  | 2342/3282 [02:19<01:01, 15.23it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████▏  | 2344/3282 [02:19<00:57, 16.17it/s]\u001b[A\n",
            "Epoch: 1:  71%|███████▏  | 2346/3282 [02:19<01:03, 14.67it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2349/3282 [02:19<01:01, 15.05it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2351/3282 [02:20<00:58, 15.97it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2353/3282 [02:20<00:57, 16.07it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2356/3282 [02:20<00:55, 16.81it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2358/3282 [02:20<01:01, 15.14it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2361/3282 [02:20<01:02, 14.72it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2364/3282 [02:20<00:55, 16.49it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2366/3282 [02:20<00:59, 15.42it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2369/3282 [02:21<00:57, 15.84it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2372/3282 [02:21<00:51, 17.52it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2374/3282 [02:21<00:54, 16.77it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2376/3282 [02:21<00:52, 17.24it/s]\u001b[A\n",
            "Epoch: 1:  72%|███████▏  | 2378/3282 [02:21<00:55, 16.33it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2380/3282 [02:21<00:54, 16.60it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2382/3282 [02:21<00:58, 15.29it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2384/3282 [02:22<00:56, 15.86it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2386/3282 [02:22<00:56, 15.97it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2388/3282 [02:22<00:54, 16.40it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2390/3282 [02:22<00:55, 16.04it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2392/3282 [02:22<00:53, 16.51it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2394/3282 [02:22<00:55, 16.09it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2396/3282 [02:22<00:53, 16.53it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2398/3282 [02:22<00:54, 16.11it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2400/3282 [02:23<00:52, 16.95it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2402/3282 [02:23<00:54, 16.24it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2404/3282 [02:23<00:53, 16.36it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2406/3282 [02:23<00:53, 16.38it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2409/3282 [02:23<00:57, 15.06it/s]\u001b[A\n",
            "Epoch: 1:  73%|███████▎  | 2412/3282 [02:23<00:48, 17.97it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▎  | 2414/3282 [02:23<00:50, 17.26it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▎  | 2416/3282 [02:23<00:52, 16.62it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▎  | 2418/3282 [02:24<00:50, 17.21it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▍  | 2421/3282 [02:24<00:46, 18.52it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▍  | 2424/3282 [02:24<00:47, 17.98it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▍  | 2426/3282 [02:24<00:49, 17.30it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▍  | 2428/3282 [02:24<00:53, 15.98it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▍  | 2430/3282 [02:24<00:54, 15.59it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▍  | 2433/3282 [02:25<00:52, 16.06it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▍  | 2436/3282 [02:25<00:47, 17.97it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▍  | 2438/3282 [02:25<00:51, 16.38it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▍  | 2441/3282 [02:25<00:49, 17.05it/s]\u001b[A\n",
            "Epoch: 1:  74%|███████▍  | 2445/3282 [02:25<00:45, 18.33it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▍  | 2448/3282 [02:25<00:40, 20.38it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▍  | 2451/3282 [02:25<00:44, 18.70it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▍  | 2453/3282 [02:26<00:46, 17.73it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▍  | 2456/3282 [02:26<00:40, 20.37it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▍  | 2459/3282 [02:26<00:45, 18.05it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▍  | 2461/3282 [02:26<00:52, 15.69it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▌  | 2464/3282 [02:26<00:44, 18.46it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▌  | 2467/3282 [02:26<00:44, 18.21it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▌  | 2469/3282 [02:27<00:50, 16.06it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▌  | 2472/3282 [02:27<00:45, 17.66it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▌  | 2474/3282 [02:27<00:49, 16.39it/s]\u001b[A\n",
            "Epoch: 1:  75%|███████▌  | 2476/3282 [02:27<00:49, 16.15it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▌  | 2478/3282 [02:27<00:51, 15.74it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▌  | 2481/3282 [02:27<00:49, 16.11it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▌  | 2484/3282 [02:27<00:42, 18.78it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▌  | 2486/3282 [02:27<00:42, 18.78it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▌  | 2489/3282 [02:28<00:43, 18.29it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▌  | 2492/3282 [02:28<00:40, 19.33it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▌  | 2494/3282 [02:28<00:46, 17.03it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▌  | 2496/3282 [02:28<00:45, 17.20it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▌  | 2498/3282 [02:28<00:48, 16.15it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▌  | 2501/3282 [02:28<00:46, 16.93it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▋  | 2504/3282 [02:29<00:44, 17.53it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▋  | 2506/3282 [02:29<00:43, 17.99it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▋  | 2508/3282 [02:29<00:42, 18.28it/s]\u001b[A\n",
            "Epoch: 1:  76%|███████▋  | 2510/3282 [02:29<00:43, 17.82it/s]\u001b[A\n",
            "Epoch: 1:  77%|███████▋  | 2512/3282 [02:29<00:46, 16.56it/s]\u001b[A\n",
            "Epoch: 1:  77%|███████▋  | 2514/3282 [02:29<00:44, 17.40it/s]\u001b[A\n",
            "Epoch: 1:  77%|███████▋  | 2517/3282 [02:29<00:45, 16.64it/s]\u001b[A\n",
            "Epoch: 1:  77%|███████▋  | 2520/3282 [02:29<00:40, 18.69it/s]\u001b[A\n",
            "Epoch: 1:  77%|███████▋  | 2522/3282 [02:30<00:41, 18.52it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1450 Task: NER Avg.Loss: 5.746678289142437e-05 Task Loss: 0.1448162943124771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  77%|███████▋  | 2525/3282 [02:30<00:40, 18.64it/s]\u001b[A\n",
            "Epoch: 1:  77%|███████▋  | 2528/3282 [02:30<00:38, 19.74it/s]\u001b[A\n",
            "Epoch: 1:  77%|███████▋  | 2530/3282 [02:30<00:45, 16.42it/s]\u001b[A\n",
            "Epoch: 1:  77%|███████▋  | 2533/3282 [02:30<00:47, 15.75it/s]\u001b[A\n",
            "Epoch: 1:  77%|███████▋  | 2536/3282 [02:30<00:40, 18.49it/s]\u001b[A\n",
            "Epoch: 1:  77%|███████▋  | 2539/3282 [02:30<00:41, 17.76it/s]\u001b[A\n",
            "Epoch: 1:  77%|███████▋  | 2541/3282 [02:31<00:46, 15.86it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2544/3282 [02:31<00:44, 16.70it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2546/3282 [02:31<00:45, 16.10it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2548/3282 [02:31<00:43, 16.70it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2550/3282 [02:31<00:45, 15.98it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2553/3282 [02:31<00:45, 16.19it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2556/3282 [02:31<00:38, 18.83it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2558/3282 [02:32<00:41, 17.60it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2561/3282 [02:32<00:41, 17.49it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2564/3282 [02:32<00:39, 18.22it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2566/3282 [02:32<00:41, 17.20it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2569/3282 [02:32<00:42, 16.75it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2572/3282 [02:32<00:39, 17.83it/s]\u001b[A\n",
            "Epoch: 1:  78%|███████▊  | 2574/3282 [02:33<00:43, 16.41it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▊  | 2577/3282 [02:33<00:42, 16.55it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▊  | 2580/3282 [02:33<00:37, 18.85it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▊  | 2582/3282 [02:33<00:41, 16.78it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▉  | 2585/3282 [02:33<00:44, 15.57it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▉  | 2588/3282 [02:33<00:38, 18.17it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▉  | 2590/3282 [02:33<00:40, 17.13it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▉  | 2592/3282 [02:34<00:39, 17.47it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▉  | 2594/3282 [02:34<00:40, 16.86it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▉  | 2597/3282 [02:34<00:37, 18.03it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▉  | 2600/3282 [02:34<00:33, 20.59it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▉  | 2603/3282 [02:34<00:40, 16.65it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▉  | 2605/3282 [02:34<00:42, 15.78it/s]\u001b[A\n",
            "Epoch: 1:  79%|███████▉  | 2608/3282 [02:35<00:37, 18.07it/s]\u001b[A\n",
            "Epoch: 1:  80%|███████▉  | 2610/3282 [02:35<00:38, 17.27it/s]\u001b[A\n",
            "Epoch: 1:  80%|███████▉  | 2612/3282 [02:35<00:38, 17.22it/s]\u001b[A\n",
            "Epoch: 1:  80%|███████▉  | 2614/3282 [02:35<00:39, 16.86it/s]\u001b[A\n",
            "Epoch: 1:  80%|███████▉  | 2617/3282 [02:35<00:35, 18.58it/s]\u001b[A\n",
            "Epoch: 1:  80%|███████▉  | 2620/3282 [02:35<00:34, 19.14it/s]\u001b[A\n",
            "Epoch: 1:  80%|███████▉  | 2622/3282 [02:35<00:34, 19.14it/s]\u001b[A\n",
            "Epoch: 1:  80%|███████▉  | 2625/3282 [02:35<00:38, 17.03it/s]\u001b[A\n",
            "Epoch: 1:  80%|████████  | 2628/3282 [02:36<00:32, 19.85it/s]\u001b[A\n",
            "Epoch: 1:  80%|████████  | 2631/3282 [02:36<00:32, 19.97it/s]\u001b[A\n",
            "Epoch: 1:  80%|████████  | 2634/3282 [02:36<00:38, 16.90it/s]\u001b[A\n",
            "Epoch: 1:  80%|████████  | 2637/3282 [02:36<00:38, 16.77it/s]\u001b[A\n",
            "Epoch: 1:  80%|████████  | 2641/3282 [02:36<00:37, 17.14it/s]\u001b[A\n",
            "Epoch: 1:  81%|████████  | 2644/3282 [02:36<00:32, 19.47it/s]\u001b[A\n",
            "Epoch: 1:  81%|████████  | 2647/3282 [02:37<00:32, 19.36it/s]\u001b[A\n",
            "Epoch: 1:  81%|████████  | 2650/3282 [02:37<00:30, 20.49it/s]\u001b[A\n",
            "Epoch: 1:  81%|████████  | 2653/3282 [02:37<00:37, 16.82it/s]\u001b[A\n",
            "Epoch: 1:  81%|████████  | 2657/3282 [02:37<00:36, 17.15it/s]\u001b[A\n",
            "Epoch: 1:  81%|████████  | 2660/3282 [02:37<00:32, 19.04it/s]\u001b[A\n",
            "Epoch: 1:  81%|████████  | 2663/3282 [02:37<00:31, 19.60it/s]\u001b[A\n",
            "Epoch: 1:  81%|████████  | 2666/3282 [02:38<00:31, 19.39it/s]\u001b[A\n",
            "Epoch: 1:  81%|████████▏ | 2669/3282 [02:38<00:35, 17.11it/s]\u001b[A\n",
            "Epoch: 1:  81%|████████▏ | 2672/3282 [02:38<00:31, 19.31it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2675/3282 [02:38<00:34, 17.46it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2677/3282 [02:38<00:35, 17.14it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2680/3282 [02:38<00:33, 18.21it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2682/3282 [02:39<00:33, 17.96it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2684/3282 [02:39<00:34, 17.28it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2686/3282 [02:39<00:36, 16.52it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2689/3282 [02:39<00:34, 16.98it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2692/3282 [02:39<00:32, 18.30it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2694/3282 [02:39<00:34, 16.95it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2697/3282 [02:39<00:34, 17.16it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2700/3282 [02:40<00:30, 18.89it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2702/3282 [02:40<00:33, 17.16it/s]\u001b[A\n",
            "Epoch: 1:  82%|████████▏ | 2705/3282 [02:40<00:33, 17.31it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2708/3282 [02:40<00:30, 18.91it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2710/3282 [02:40<00:33, 16.87it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2713/3282 [02:40<00:35, 16.05it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2716/3282 [02:41<00:31, 17.99it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2718/3282 [02:41<00:33, 16.82it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2720/3282 [02:41<00:35, 15.99it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2722/3282 [02:41<00:33, 16.62it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1500 Task: intent Avg.Loss: 3.584088744901237e-06 Task Loss: 0.009748721495270729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  83%|████████▎ | 2725/3282 [02:41<00:32, 17.38it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2728/3282 [02:41<00:27, 20.09it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2731/3282 [02:41<00:26, 20.63it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2734/3282 [02:42<00:31, 17.67it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2737/3282 [02:42<00:32, 16.92it/s]\u001b[A\n",
            "Epoch: 1:  83%|████████▎ | 2740/3282 [02:42<00:29, 18.36it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▎ | 2742/3282 [02:42<00:31, 17.03it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▎ | 2745/3282 [02:42<00:32, 16.67it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▎ | 2748/3282 [02:42<00:31, 17.01it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▍ | 2750/3282 [02:42<00:30, 17.53it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▍ | 2753/3282 [02:43<00:31, 16.99it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▍ | 2756/3282 [02:43<00:28, 18.57it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▍ | 2758/3282 [02:43<00:29, 17.77it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▍ | 2760/3282 [02:43<00:30, 17.29it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▍ | 2762/3282 [02:43<00:31, 16.67it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▍ | 2765/3282 [02:43<00:31, 16.38it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▍ | 2768/3282 [02:43<00:28, 18.29it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▍ | 2770/3282 [02:44<00:29, 17.46it/s]\u001b[A\n",
            "Epoch: 1:  84%|████████▍ | 2773/3282 [02:44<00:29, 17.33it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▍ | 2776/3282 [02:44<00:25, 20.09it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▍ | 2779/3282 [02:44<00:27, 18.17it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▍ | 2781/3282 [02:44<00:30, 16.63it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▍ | 2785/3282 [02:44<00:25, 19.56it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▍ | 2788/3282 [02:45<00:23, 20.86it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▌ | 2791/3282 [02:45<00:24, 20.15it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▌ | 2794/3282 [02:45<00:25, 19.01it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▌ | 2797/3282 [02:45<00:26, 18.04it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▌ | 2800/3282 [02:45<00:24, 19.39it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▌ | 2802/3282 [02:45<00:27, 17.18it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▌ | 2804/3282 [02:45<00:27, 17.38it/s]\u001b[A\n",
            "Epoch: 1:  85%|████████▌ | 2806/3282 [02:46<00:27, 17.25it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▌ | 2809/3282 [02:46<00:27, 17.28it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▌ | 2812/3282 [02:46<00:23, 19.83it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▌ | 2815/3282 [02:46<00:24, 19.20it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▌ | 2817/3282 [02:46<00:25, 17.93it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▌ | 2819/3282 [02:46<00:25, 18.23it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▌ | 2821/3282 [02:46<00:26, 17.08it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▌ | 2824/3282 [02:47<00:23, 19.63it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▌ | 2827/3282 [02:47<00:26, 17.26it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▌ | 2829/3282 [02:47<00:28, 15.83it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▋ | 2832/3282 [02:47<00:26, 17.17it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▋ | 2835/3282 [02:47<00:24, 18.41it/s]\u001b[A\n",
            "Epoch: 1:  86%|████████▋ | 2837/3282 [02:47<00:27, 15.91it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2840/3282 [02:47<00:25, 17.65it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2842/3282 [02:48<00:25, 16.97it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2844/3282 [02:48<00:25, 17.49it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2846/3282 [02:48<00:27, 15.65it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2849/3282 [02:48<00:29, 14.46it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2852/3282 [02:48<00:25, 16.68it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2854/3282 [02:48<00:25, 16.59it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2856/3282 [02:48<00:26, 16.38it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2858/3282 [02:49<00:28, 14.79it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2860/3282 [02:49<00:26, 15.81it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2862/3282 [02:49<00:27, 15.07it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2864/3282 [02:49<00:27, 15.41it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2866/3282 [02:49<00:26, 15.53it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2868/3282 [02:49<00:25, 16.26it/s]\u001b[A\n",
            "Epoch: 1:  87%|████████▋ | 2870/3282 [02:49<00:27, 15.13it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2873/3282 [02:50<00:26, 15.64it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2875/3282 [02:50<00:24, 16.49it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2877/3282 [02:50<00:26, 15.22it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2879/3282 [02:50<00:24, 16.24it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2881/3282 [02:50<00:24, 16.08it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2884/3282 [02:50<00:22, 17.91it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2886/3282 [02:50<00:24, 16.16it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2888/3282 [02:51<00:23, 16.82it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2890/3282 [02:51<00:24, 15.98it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2892/3282 [02:51<00:23, 16.89it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2894/3282 [02:51<00:24, 15.59it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2897/3282 [02:51<00:24, 15.92it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2899/3282 [02:51<00:23, 16.42it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2901/3282 [02:51<00:25, 15.10it/s]\u001b[A\n",
            "Epoch: 1:  88%|████████▊ | 2903/3282 [02:51<00:24, 15.79it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▊ | 2905/3282 [02:52<00:24, 15.36it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▊ | 2908/3282 [02:52<00:21, 17.41it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▊ | 2910/3282 [02:52<00:23, 15.81it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▊ | 2912/3282 [02:52<00:22, 16.65it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▉ | 2914/3282 [02:52<00:25, 14.68it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▉ | 2916/3282 [02:52<00:24, 14.95it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▉ | 2918/3282 [02:52<00:26, 13.94it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▉ | 2920/3282 [02:53<00:24, 14.94it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▉ | 2922/3282 [02:53<00:24, 14.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps: 1550 Task: frag Avg.Loss: 5.361897024158679e-07 Task Loss: 0.001565673854202032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch: 1:  89%|████████▉ | 2924/3282 [02:53<00:22, 15.72it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▉ | 2926/3282 [02:53<00:23, 15.41it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▉ | 2928/3282 [02:53<00:22, 15.91it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▉ | 2930/3282 [02:53<00:23, 15.01it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▉ | 2932/3282 [02:53<00:21, 16.17it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▉ | 2934/3282 [02:53<00:21, 15.93it/s]\u001b[A\n",
            "Epoch: 1:  89%|████████▉ | 2937/3282 [02:54<00:21, 16.34it/s]\u001b[A\n",
            "Epoch: 1:  90%|████████▉ | 2940/3282 [02:54<00:19, 17.23it/s]\u001b[A\n",
            "Epoch: 1:  90%|████████▉ | 2942/3282 [02:54<00:19, 17.59it/s]\u001b[A\n",
            "Epoch: 1:  90%|████████▉ | 2944/3282 [02:54<00:19, 17.05it/s]\u001b[A\n",
            "Epoch: 1:  90%|████████▉ | 2946/3282 [02:54<00:21, 15.39it/s]\u001b[A\n",
            "Epoch: 1:  90%|████████▉ | 2948/3282 [02:54<00:20, 16.30it/s]\u001b[A\n",
            "Epoch: 1:  90%|████████▉ | 2950/3282 [02:54<00:21, 15.39it/s]\u001b[A\n",
            "Epoch: 1:  90%|████████▉ | 2952/3282 [02:55<00:20, 16.17it/s]\u001b[A\n",
            "Epoch: 1:  90%|█████████ | 2954/3282 [02:55<00:22, 14.33it/s]\u001b[A\n",
            "Epoch: 1:  90%|█████████ | 2957/3282 [02:55<00:20, 15.64it/s]\u001b[A\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f733d86fb8b94a2b9ed674cfb5e3bce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e890b7f419054f068cb86a5812c8f797",
              "IPY_MODEL_3efc1f5ebc63408d83d04a857dd43153",
              "IPY_MODEL_6c2fc92c6b2e4ed0844bd420329002c2"
            ],
            "layout": "IPY_MODEL_e65287369bd845e788dba589ffa9aab1"
          }
        },
        "e890b7f419054f068cb86a5812c8f797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1ffe30a6084b14be136aee49f8ac70",
            "placeholder": "​",
            "style": "IPY_MODEL_85fa1712b39f411b88bf30c277459eaf",
            "value": "Downloading: 100%"
          }
        },
        "3efc1f5ebc63408d83d04a857dd43153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f3eadfeb95846e3b29d37c0d2e2f12d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffc0adaadb464f45ae5440c8f5cd6c4c",
            "value": 231508
          }
        },
        "6c2fc92c6b2e4ed0844bd420329002c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5388bcd74595492ab8b7b1b179901c2d",
            "placeholder": "​",
            "style": "IPY_MODEL_08d087799b5d455b8d3f66489a826024",
            "value": " 232k/232k [00:00&lt;00:00, 265kB/s]"
          }
        },
        "e65287369bd845e788dba589ffa9aab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1ffe30a6084b14be136aee49f8ac70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85fa1712b39f411b88bf30c277459eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f3eadfeb95846e3b29d37c0d2e2f12d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffc0adaadb464f45ae5440c8f5cd6c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5388bcd74595492ab8b7b1b179901c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d087799b5d455b8d3f66489a826024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fedc3d398724d0f8bed49cd911de2b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45e90efa847b4d99a7f9cd13c19d60d0",
              "IPY_MODEL_36f45980158f43849ffcc42d17ad7b95",
              "IPY_MODEL_218438bccbea49d19130778dd94eb2fb"
            ],
            "layout": "IPY_MODEL_9c3ffd226cd143d7a00f1e860095f1d0"
          }
        },
        "45e90efa847b4d99a7f9cd13c19d60d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_938a9c002ae3484c98e1d8e7f2800020",
            "placeholder": "​",
            "style": "IPY_MODEL_3da3bb322f7b48268aa526bae908d896",
            "value": "Downloading: 100%"
          }
        },
        "36f45980158f43849ffcc42d17ad7b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1c2112ba68a435484510d3972d4334e",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6084a389ce34f6c96e43ede7c777490",
            "value": 28
          }
        },
        "218438bccbea49d19130778dd94eb2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d38471034b0049caa1eec3bc67ec143d",
            "placeholder": "​",
            "style": "IPY_MODEL_733fcc54ca794c65a344a3e3ae6b6d08",
            "value": " 28.0/28.0 [00:00&lt;00:00, 522B/s]"
          }
        },
        "9c3ffd226cd143d7a00f1e860095f1d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "938a9c002ae3484c98e1d8e7f2800020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3da3bb322f7b48268aa526bae908d896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1c2112ba68a435484510d3972d4334e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6084a389ce34f6c96e43ede7c777490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d38471034b0049caa1eec3bc67ec143d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "733fcc54ca794c65a344a3e3ae6b6d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66084c61bf2940e5b42a06a392aa7f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ecd7dcff5b241b980ebb81ee4a0c7c3",
              "IPY_MODEL_4ed60e32dc79445b84f96a4d9041bde0",
              "IPY_MODEL_397154c194284c6c8a7a1176c21fd562"
            ],
            "layout": "IPY_MODEL_cda7aeaedb4b47e9babff6cff641c60c"
          }
        },
        "3ecd7dcff5b241b980ebb81ee4a0c7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47e9015c5cbb40c38b7afb44b290b92f",
            "placeholder": "​",
            "style": "IPY_MODEL_baeca601da7844019c56bf131f25c80d",
            "value": "Downloading: 100%"
          }
        },
        "4ed60e32dc79445b84f96a4d9041bde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_573ebe12883043acbd8d29f8b8b37398",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6f6b2d3686a4b3b9245d48ff5458242",
            "value": 570
          }
        },
        "397154c194284c6c8a7a1176c21fd562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1be758c33811499ba5cedae771ac916a",
            "placeholder": "​",
            "style": "IPY_MODEL_65ccd82bb0994e92a51f5ac88716559a",
            "value": " 570/570 [00:00&lt;00:00, 5.98kB/s]"
          }
        },
        "cda7aeaedb4b47e9babff6cff641c60c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e9015c5cbb40c38b7afb44b290b92f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baeca601da7844019c56bf131f25c80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "573ebe12883043acbd8d29f8b8b37398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6f6b2d3686a4b3b9245d48ff5458242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1be758c33811499ba5cedae771ac916a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65ccd82bb0994e92a51f5ac88716559a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}